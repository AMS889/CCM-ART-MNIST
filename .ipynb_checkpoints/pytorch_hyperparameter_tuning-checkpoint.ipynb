{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import helper\n",
    "import models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import importlib as imp\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms, utils\n",
    "\n",
    "rs = 2018\n",
    "random.seed(rs)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the tensor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda: False\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print('Using cuda: {}'.format(use_cuda))\n",
    "torch.manual_seed(rs)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "batch_size = 1000\n",
    "n_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.EMNIST('data/', train=True, split='digits', download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.EMNIST('data/', train=False, split='digits', transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader_ordered = torch.utils.data.DataLoader(\n",
    "    datasets.EMNIST('data/', train=False, split='digits', transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=len(test_loader.dataset), shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing across all parameters\n",
    "\n",
    "**Note:** Netx represents an x layer network between 1 and 4 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/240000 (0%)]\tLoss: 2.288772\n",
      "Train Epoch: 0 [1000/240000 (0%)]\tLoss: 2.301336\n",
      "Train Epoch: 0 [2000/240000 (1%)]\tLoss: 2.302456\n",
      "Train Epoch: 0 [3000/240000 (1%)]\tLoss: 2.270942\n",
      "Train Epoch: 0 [4000/240000 (2%)]\tLoss: 2.260028\n",
      "Train Epoch: 0 [5000/240000 (2%)]\tLoss: 2.214829\n",
      "Train Epoch: 0 [6000/240000 (2%)]\tLoss: 2.240728\n",
      "Train Epoch: 0 [7000/240000 (3%)]\tLoss: 2.221994\n",
      "Train Epoch: 0 [8000/240000 (3%)]\tLoss: 2.235784\n",
      "Train Epoch: 0 [9000/240000 (4%)]\tLoss: 2.167164\n",
      "Train Epoch: 0 [10000/240000 (4%)]\tLoss: 2.165949\n",
      "Train Epoch: 0 [11000/240000 (5%)]\tLoss: 2.139379\n",
      "Train Epoch: 0 [12000/240000 (5%)]\tLoss: 2.134699\n",
      "Train Epoch: 0 [13000/240000 (5%)]\tLoss: 2.113478\n",
      "Train Epoch: 0 [14000/240000 (6%)]\tLoss: 2.101620\n",
      "Train Epoch: 0 [15000/240000 (6%)]\tLoss: 2.052360\n",
      "Train Epoch: 0 [16000/240000 (7%)]\tLoss: 2.043880\n",
      "Train Epoch: 0 [17000/240000 (7%)]\tLoss: 2.006132\n",
      "Train Epoch: 0 [18000/240000 (8%)]\tLoss: 2.043585\n",
      "Train Epoch: 0 [19000/240000 (8%)]\tLoss: 1.992280\n",
      "Train Epoch: 0 [20000/240000 (8%)]\tLoss: 1.962119\n",
      "Train Epoch: 0 [21000/240000 (9%)]\tLoss: 1.930278\n",
      "Train Epoch: 0 [22000/240000 (9%)]\tLoss: 1.923196\n",
      "Train Epoch: 0 [23000/240000 (10%)]\tLoss: 1.896367\n",
      "Train Epoch: 0 [24000/240000 (10%)]\tLoss: 1.836204\n",
      "Train Epoch: 0 [25000/240000 (10%)]\tLoss: 1.805088\n",
      "Train Epoch: 0 [26000/240000 (11%)]\tLoss: 1.700998\n",
      "Train Epoch: 0 [27000/240000 (11%)]\tLoss: 1.646362\n",
      "Train Epoch: 0 [28000/240000 (12%)]\tLoss: 1.601627\n",
      "Train Epoch: 0 [29000/240000 (12%)]\tLoss: 1.548129\n",
      "Train Epoch: 0 [30000/240000 (12%)]\tLoss: 1.537740\n",
      "Train Epoch: 0 [31000/240000 (13%)]\tLoss: 1.561917\n",
      "Train Epoch: 0 [32000/240000 (13%)]\tLoss: 1.559976\n",
      "Train Epoch: 0 [33000/240000 (14%)]\tLoss: 1.574304\n",
      "Train Epoch: 0 [34000/240000 (14%)]\tLoss: 1.385803\n",
      "Train Epoch: 0 [35000/240000 (15%)]\tLoss: 1.329401\n",
      "Train Epoch: 0 [36000/240000 (15%)]\tLoss: 1.340046\n",
      "Train Epoch: 0 [37000/240000 (15%)]\tLoss: 1.323895\n",
      "Train Epoch: 0 [38000/240000 (16%)]\tLoss: 1.259237\n",
      "Train Epoch: 0 [39000/240000 (16%)]\tLoss: 1.274411\n",
      "Train Epoch: 0 [40000/240000 (17%)]\tLoss: 1.138280\n",
      "Train Epoch: 0 [41000/240000 (17%)]\tLoss: 1.188877\n",
      "Train Epoch: 0 [42000/240000 (18%)]\tLoss: 0.985774\n",
      "Train Epoch: 0 [43000/240000 (18%)]\tLoss: 1.090977\n",
      "Train Epoch: 0 [44000/240000 (18%)]\tLoss: 1.121521\n",
      "Train Epoch: 0 [45000/240000 (19%)]\tLoss: 0.976839\n",
      "Train Epoch: 0 [46000/240000 (19%)]\tLoss: 0.993984\n",
      "Train Epoch: 0 [47000/240000 (20%)]\tLoss: 1.001174\n",
      "Train Epoch: 0 [48000/240000 (20%)]\tLoss: 1.019243\n",
      "Train Epoch: 0 [49000/240000 (20%)]\tLoss: 0.953670\n",
      "Train Epoch: 0 [50000/240000 (21%)]\tLoss: 1.052930\n",
      "Train Epoch: 0 [51000/240000 (21%)]\tLoss: 0.919654\n",
      "Train Epoch: 0 [52000/240000 (22%)]\tLoss: 0.788167\n",
      "Train Epoch: 0 [53000/240000 (22%)]\tLoss: 0.811822\n",
      "Train Epoch: 0 [54000/240000 (22%)]\tLoss: 0.779269\n",
      "Train Epoch: 0 [55000/240000 (23%)]\tLoss: 0.874535\n",
      "Train Epoch: 0 [56000/240000 (23%)]\tLoss: 0.742983\n",
      "Train Epoch: 0 [57000/240000 (24%)]\tLoss: 0.727238\n",
      "Train Epoch: 0 [58000/240000 (24%)]\tLoss: 0.773834\n",
      "Train Epoch: 0 [59000/240000 (25%)]\tLoss: 0.800833\n",
      "Train Epoch: 0 [60000/240000 (25%)]\tLoss: 0.651234\n",
      "Train Epoch: 0 [61000/240000 (25%)]\tLoss: 0.699578\n",
      "Train Epoch: 0 [62000/240000 (26%)]\tLoss: 0.706861\n",
      "Train Epoch: 0 [63000/240000 (26%)]\tLoss: 0.656575\n",
      "Train Epoch: 0 [64000/240000 (27%)]\tLoss: 0.656524\n",
      "Train Epoch: 0 [65000/240000 (27%)]\tLoss: 0.598179\n",
      "Train Epoch: 0 [66000/240000 (28%)]\tLoss: 0.587409\n",
      "Train Epoch: 0 [67000/240000 (28%)]\tLoss: 0.553168\n",
      "Train Epoch: 0 [68000/240000 (28%)]\tLoss: 0.643304\n",
      "Train Epoch: 0 [69000/240000 (29%)]\tLoss: 0.548032\n",
      "Train Epoch: 0 [70000/240000 (29%)]\tLoss: 0.732486\n",
      "Train Epoch: 0 [71000/240000 (30%)]\tLoss: 0.665138\n",
      "Train Epoch: 0 [72000/240000 (30%)]\tLoss: 0.588072\n",
      "Train Epoch: 0 [73000/240000 (30%)]\tLoss: 0.562572\n",
      "Train Epoch: 0 [74000/240000 (31%)]\tLoss: 0.638964\n",
      "Train Epoch: 0 [75000/240000 (31%)]\tLoss: 0.505248\n",
      "Train Epoch: 0 [76000/240000 (32%)]\tLoss: 0.493701\n",
      "Train Epoch: 0 [77000/240000 (32%)]\tLoss: 0.556995\n",
      "Train Epoch: 0 [78000/240000 (32%)]\tLoss: 0.577401\n",
      "Train Epoch: 0 [79000/240000 (33%)]\tLoss: 0.577890\n",
      "Train Epoch: 0 [80000/240000 (33%)]\tLoss: 0.618141\n",
      "Train Epoch: 0 [81000/240000 (34%)]\tLoss: 0.554506\n",
      "Train Epoch: 0 [82000/240000 (34%)]\tLoss: 0.567139\n",
      "Train Epoch: 0 [83000/240000 (35%)]\tLoss: 0.468023\n",
      "Train Epoch: 0 [84000/240000 (35%)]\tLoss: 0.418422\n",
      "Train Epoch: 0 [85000/240000 (35%)]\tLoss: 0.551779\n",
      "Train Epoch: 0 [86000/240000 (36%)]\tLoss: 0.645009\n",
      "Train Epoch: 0 [87000/240000 (36%)]\tLoss: 0.548136\n",
      "Train Epoch: 0 [88000/240000 (37%)]\tLoss: 0.780268\n",
      "Train Epoch: 0 [89000/240000 (37%)]\tLoss: 0.518209\n",
      "Train Epoch: 0 [90000/240000 (38%)]\tLoss: 0.669553\n",
      "Train Epoch: 0 [91000/240000 (38%)]\tLoss: 0.487385\n",
      "Train Epoch: 0 [92000/240000 (38%)]\tLoss: 0.479005\n",
      "Train Epoch: 0 [93000/240000 (39%)]\tLoss: 0.542397\n",
      "Train Epoch: 0 [94000/240000 (39%)]\tLoss: 0.582251\n",
      "Train Epoch: 0 [95000/240000 (40%)]\tLoss: 0.528706\n",
      "Train Epoch: 0 [96000/240000 (40%)]\tLoss: 0.583490\n",
      "Train Epoch: 0 [97000/240000 (40%)]\tLoss: 0.460346\n",
      "Train Epoch: 0 [98000/240000 (41%)]\tLoss: 0.474931\n",
      "Train Epoch: 0 [99000/240000 (41%)]\tLoss: 0.519355\n",
      "Train Epoch: 0 [100000/240000 (42%)]\tLoss: 0.571292\n",
      "Train Epoch: 0 [101000/240000 (42%)]\tLoss: 0.541823\n",
      "Train Epoch: 0 [102000/240000 (42%)]\tLoss: 0.389674\n",
      "Train Epoch: 0 [103000/240000 (43%)]\tLoss: 0.480755\n",
      "Train Epoch: 0 [104000/240000 (43%)]\tLoss: 0.366005\n",
      "Train Epoch: 0 [105000/240000 (44%)]\tLoss: 0.332885\n",
      "Train Epoch: 0 [106000/240000 (44%)]\tLoss: 0.405555\n",
      "Train Epoch: 0 [107000/240000 (45%)]\tLoss: 0.479517\n",
      "Train Epoch: 0 [108000/240000 (45%)]\tLoss: 0.480100\n",
      "Train Epoch: 0 [109000/240000 (45%)]\tLoss: 0.442843\n",
      "Train Epoch: 0 [110000/240000 (46%)]\tLoss: 0.369907\n",
      "Train Epoch: 0 [111000/240000 (46%)]\tLoss: 0.472088\n",
      "Train Epoch: 0 [112000/240000 (47%)]\tLoss: 0.440176\n",
      "Train Epoch: 0 [113000/240000 (47%)]\tLoss: 0.493305\n",
      "Train Epoch: 0 [114000/240000 (48%)]\tLoss: 0.413995\n",
      "Train Epoch: 0 [115000/240000 (48%)]\tLoss: 0.396318\n",
      "Train Epoch: 0 [116000/240000 (48%)]\tLoss: 0.331025\n",
      "Train Epoch: 0 [117000/240000 (49%)]\tLoss: 0.419200\n",
      "Train Epoch: 0 [118000/240000 (49%)]\tLoss: 0.529226\n",
      "Train Epoch: 0 [119000/240000 (50%)]\tLoss: 0.428097\n",
      "Train Epoch: 0 [120000/240000 (50%)]\tLoss: 0.347930\n",
      "Train Epoch: 0 [121000/240000 (50%)]\tLoss: 0.427296\n",
      "Train Epoch: 0 [122000/240000 (51%)]\tLoss: 0.435627\n",
      "Train Epoch: 0 [123000/240000 (51%)]\tLoss: 0.463467\n",
      "Train Epoch: 0 [124000/240000 (52%)]\tLoss: 0.338786\n",
      "Train Epoch: 0 [125000/240000 (52%)]\tLoss: 0.405346\n",
      "Train Epoch: 0 [126000/240000 (52%)]\tLoss: 0.412974\n",
      "Train Epoch: 0 [127000/240000 (53%)]\tLoss: 0.560130\n",
      "Train Epoch: 0 [128000/240000 (53%)]\tLoss: 0.429868\n",
      "Train Epoch: 0 [129000/240000 (54%)]\tLoss: 0.428781\n",
      "Train Epoch: 0 [130000/240000 (54%)]\tLoss: 0.313547\n",
      "Train Epoch: 0 [131000/240000 (55%)]\tLoss: 0.309826\n",
      "Train Epoch: 0 [132000/240000 (55%)]\tLoss: 0.419265\n",
      "Train Epoch: 0 [133000/240000 (55%)]\tLoss: 0.390452\n",
      "Train Epoch: 0 [134000/240000 (56%)]\tLoss: 0.305773\n",
      "Train Epoch: 0 [135000/240000 (56%)]\tLoss: 0.315720\n",
      "Train Epoch: 0 [136000/240000 (57%)]\tLoss: 0.473724\n",
      "Train Epoch: 0 [137000/240000 (57%)]\tLoss: 0.459417\n",
      "Train Epoch: 0 [138000/240000 (58%)]\tLoss: 0.470351\n",
      "Train Epoch: 0 [139000/240000 (58%)]\tLoss: 0.619795\n",
      "Train Epoch: 0 [140000/240000 (58%)]\tLoss: 0.263353\n",
      "Train Epoch: 0 [141000/240000 (59%)]\tLoss: 0.428423\n",
      "Train Epoch: 0 [142000/240000 (59%)]\tLoss: 0.320934\n",
      "Train Epoch: 0 [143000/240000 (60%)]\tLoss: 0.360733\n",
      "Train Epoch: 0 [144000/240000 (60%)]\tLoss: 0.339975\n",
      "Train Epoch: 0 [145000/240000 (60%)]\tLoss: 0.461828\n",
      "Train Epoch: 0 [146000/240000 (61%)]\tLoss: 0.366057\n",
      "Train Epoch: 0 [147000/240000 (61%)]\tLoss: 0.495259\n",
      "Train Epoch: 0 [148000/240000 (62%)]\tLoss: 0.395410\n",
      "Train Epoch: 0 [149000/240000 (62%)]\tLoss: 0.397695\n",
      "Train Epoch: 0 [150000/240000 (62%)]\tLoss: 0.367579\n",
      "Train Epoch: 0 [151000/240000 (63%)]\tLoss: 0.433164\n",
      "Train Epoch: 0 [152000/240000 (63%)]\tLoss: 0.361840\n",
      "Train Epoch: 0 [153000/240000 (64%)]\tLoss: 0.324079\n",
      "Train Epoch: 0 [154000/240000 (64%)]\tLoss: 0.400046\n",
      "Train Epoch: 0 [155000/240000 (65%)]\tLoss: 0.492637\n",
      "Train Epoch: 0 [156000/240000 (65%)]\tLoss: 0.517063\n",
      "Train Epoch: 0 [157000/240000 (65%)]\tLoss: 0.337612\n",
      "Train Epoch: 0 [158000/240000 (66%)]\tLoss: 0.245866\n",
      "Train Epoch: 0 [159000/240000 (66%)]\tLoss: 0.392477\n",
      "Train Epoch: 0 [160000/240000 (67%)]\tLoss: 0.341020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [161000/240000 (67%)]\tLoss: 0.398805\n",
      "Train Epoch: 0 [162000/240000 (68%)]\tLoss: 0.269249\n",
      "Train Epoch: 0 [163000/240000 (68%)]\tLoss: 0.441543\n",
      "Train Epoch: 0 [164000/240000 (68%)]\tLoss: 0.397016\n",
      "Train Epoch: 0 [165000/240000 (69%)]\tLoss: 0.331120\n",
      "Train Epoch: 0 [166000/240000 (69%)]\tLoss: 0.596817\n",
      "Train Epoch: 0 [167000/240000 (70%)]\tLoss: 0.226014\n",
      "Train Epoch: 0 [168000/240000 (70%)]\tLoss: 0.386688\n",
      "Train Epoch: 0 [169000/240000 (70%)]\tLoss: 0.360820\n",
      "Train Epoch: 0 [170000/240000 (71%)]\tLoss: 0.522821\n",
      "Train Epoch: 0 [171000/240000 (71%)]\tLoss: 0.361670\n",
      "Train Epoch: 0 [172000/240000 (72%)]\tLoss: 0.405807\n",
      "Train Epoch: 0 [173000/240000 (72%)]\tLoss: 0.323116\n",
      "Train Epoch: 0 [174000/240000 (72%)]\tLoss: 0.386078\n",
      "Train Epoch: 0 [175000/240000 (73%)]\tLoss: 0.451266\n",
      "Train Epoch: 0 [176000/240000 (73%)]\tLoss: 0.341784\n",
      "Train Epoch: 0 [177000/240000 (74%)]\tLoss: 0.343701\n",
      "Train Epoch: 0 [178000/240000 (74%)]\tLoss: 0.561244\n",
      "Train Epoch: 0 [179000/240000 (75%)]\tLoss: 0.340142\n",
      "Train Epoch: 0 [180000/240000 (75%)]\tLoss: 0.327691\n",
      "Train Epoch: 0 [181000/240000 (75%)]\tLoss: 0.291816\n",
      "Train Epoch: 0 [182000/240000 (76%)]\tLoss: 0.424483\n",
      "Train Epoch: 0 [183000/240000 (76%)]\tLoss: 0.299062\n",
      "Train Epoch: 0 [184000/240000 (77%)]\tLoss: 0.419831\n",
      "Train Epoch: 0 [185000/240000 (77%)]\tLoss: 0.403538\n",
      "Train Epoch: 0 [186000/240000 (78%)]\tLoss: 0.369630\n",
      "Train Epoch: 0 [187000/240000 (78%)]\tLoss: 0.356929\n",
      "Train Epoch: 0 [188000/240000 (78%)]\tLoss: 0.260203\n",
      "Train Epoch: 0 [189000/240000 (79%)]\tLoss: 0.429135\n",
      "Train Epoch: 0 [190000/240000 (79%)]\tLoss: 0.261835\n",
      "Train Epoch: 0 [191000/240000 (80%)]\tLoss: 0.408635\n",
      "Train Epoch: 0 [192000/240000 (80%)]\tLoss: 0.345044\n",
      "Train Epoch: 0 [193000/240000 (80%)]\tLoss: 0.414552\n",
      "Train Epoch: 0 [194000/240000 (81%)]\tLoss: 0.310200\n",
      "Train Epoch: 0 [195000/240000 (81%)]\tLoss: 0.364074\n",
      "Train Epoch: 0 [196000/240000 (82%)]\tLoss: 0.272054\n",
      "Train Epoch: 0 [197000/240000 (82%)]\tLoss: 0.312600\n",
      "Train Epoch: 0 [198000/240000 (82%)]\tLoss: 0.381578\n",
      "Train Epoch: 0 [199000/240000 (83%)]\tLoss: 0.372039\n",
      "Train Epoch: 0 [200000/240000 (83%)]\tLoss: 0.418512\n",
      "Train Epoch: 0 [201000/240000 (84%)]\tLoss: 0.394372\n",
      "Train Epoch: 0 [202000/240000 (84%)]\tLoss: 0.285904\n",
      "Train Epoch: 0 [203000/240000 (85%)]\tLoss: 0.292236\n",
      "Train Epoch: 0 [204000/240000 (85%)]\tLoss: 0.375414\n",
      "Train Epoch: 0 [205000/240000 (85%)]\tLoss: 0.325531\n",
      "Train Epoch: 0 [206000/240000 (86%)]\tLoss: 0.270063\n",
      "Train Epoch: 0 [207000/240000 (86%)]\tLoss: 0.317952\n",
      "Train Epoch: 0 [208000/240000 (87%)]\tLoss: 0.223213\n",
      "Train Epoch: 0 [209000/240000 (87%)]\tLoss: 0.398180\n",
      "Train Epoch: 0 [210000/240000 (88%)]\tLoss: 0.271418\n",
      "Train Epoch: 0 [211000/240000 (88%)]\tLoss: 0.346439\n",
      "Train Epoch: 0 [212000/240000 (88%)]\tLoss: 0.248695\n",
      "Train Epoch: 0 [213000/240000 (89%)]\tLoss: 0.371152\n",
      "Train Epoch: 0 [214000/240000 (89%)]\tLoss: 0.336725\n",
      "Train Epoch: 0 [215000/240000 (90%)]\tLoss: 0.335826\n",
      "Train Epoch: 0 [216000/240000 (90%)]\tLoss: 0.350117\n",
      "Train Epoch: 0 [217000/240000 (90%)]\tLoss: 0.394901\n",
      "Train Epoch: 0 [218000/240000 (91%)]\tLoss: 0.353343\n",
      "Train Epoch: 0 [219000/240000 (91%)]\tLoss: 0.477900\n",
      "Train Epoch: 0 [220000/240000 (92%)]\tLoss: 0.375219\n",
      "Train Epoch: 0 [221000/240000 (92%)]\tLoss: 0.390007\n",
      "Train Epoch: 0 [222000/240000 (92%)]\tLoss: 0.253554\n",
      "Train Epoch: 0 [223000/240000 (93%)]\tLoss: 0.339481\n",
      "Train Epoch: 0 [224000/240000 (93%)]\tLoss: 0.188746\n",
      "Train Epoch: 0 [225000/240000 (94%)]\tLoss: 0.318909\n",
      "Train Epoch: 0 [226000/240000 (94%)]\tLoss: 0.400948\n",
      "Train Epoch: 0 [227000/240000 (95%)]\tLoss: 0.416648\n",
      "Train Epoch: 0 [228000/240000 (95%)]\tLoss: 0.346901\n",
      "Train Epoch: 0 [229000/240000 (95%)]\tLoss: 0.225484\n",
      "Train Epoch: 0 [230000/240000 (96%)]\tLoss: 0.291579\n",
      "Train Epoch: 0 [231000/240000 (96%)]\tLoss: 0.247396\n",
      "Train Epoch: 0 [232000/240000 (97%)]\tLoss: 0.250010\n",
      "Train Epoch: 0 [233000/240000 (97%)]\tLoss: 0.402851\n",
      "Train Epoch: 0 [234000/240000 (98%)]\tLoss: 0.405133\n",
      "Train Epoch: 0 [235000/240000 (98%)]\tLoss: 0.289357\n",
      "Train Epoch: 0 [236000/240000 (98%)]\tLoss: 0.354537\n",
      "Train Epoch: 0 [237000/240000 (99%)]\tLoss: 0.251570\n",
      "Train Epoch: 0 [238000/240000 (99%)]\tLoss: 0.252553\n",
      "Train Epoch: 0 [239000/240000 (100%)]\tLoss: 0.259346\n",
      "Time elapsed 0:01:08.231393\n",
      "\n",
      "Test set: Average loss: 0.2506, Accuracy: 37108.0/40000 (93%)\n",
      "\n",
      "1 of 5 100 0.2\n",
      "Train Epoch: 1 [0/240000 (0%)]\tLoss: 0.247144\n",
      "Train Epoch: 1 [1000/240000 (0%)]\tLoss: 0.217410\n",
      "Train Epoch: 1 [2000/240000 (1%)]\tLoss: 0.323281\n",
      "Train Epoch: 1 [3000/240000 (1%)]\tLoss: 0.343143\n",
      "Train Epoch: 1 [4000/240000 (2%)]\tLoss: 0.209627\n",
      "Train Epoch: 1 [5000/240000 (2%)]\tLoss: 0.263128\n",
      "Train Epoch: 1 [6000/240000 (2%)]\tLoss: 0.219614\n",
      "Train Epoch: 1 [7000/240000 (3%)]\tLoss: 0.240849\n",
      "Train Epoch: 1 [8000/240000 (3%)]\tLoss: 0.521280\n",
      "Train Epoch: 1 [9000/240000 (4%)]\tLoss: 0.250876\n",
      "Train Epoch: 1 [10000/240000 (4%)]\tLoss: 0.459171\n",
      "Train Epoch: 1 [11000/240000 (5%)]\tLoss: 0.288691\n",
      "Train Epoch: 1 [12000/240000 (5%)]\tLoss: 0.374801\n",
      "Train Epoch: 1 [13000/240000 (5%)]\tLoss: 0.323498\n",
      "Train Epoch: 1 [14000/240000 (6%)]\tLoss: 0.363440\n",
      "Train Epoch: 1 [15000/240000 (6%)]\tLoss: 0.257261\n",
      "Train Epoch: 1 [16000/240000 (7%)]\tLoss: 0.378257\n",
      "Train Epoch: 1 [17000/240000 (7%)]\tLoss: 0.237529\n",
      "Train Epoch: 1 [18000/240000 (8%)]\tLoss: 0.353562\n",
      "Train Epoch: 1 [19000/240000 (8%)]\tLoss: 0.246197\n",
      "Train Epoch: 1 [20000/240000 (8%)]\tLoss: 0.523982\n",
      "Train Epoch: 1 [21000/240000 (9%)]\tLoss: 0.321617\n",
      "Train Epoch: 1 [22000/240000 (9%)]\tLoss: 0.310160\n",
      "Train Epoch: 1 [23000/240000 (10%)]\tLoss: 0.220851\n",
      "Train Epoch: 1 [24000/240000 (10%)]\tLoss: 0.280659\n",
      "Train Epoch: 1 [25000/240000 (10%)]\tLoss: 0.227613\n",
      "Train Epoch: 1 [26000/240000 (11%)]\tLoss: 0.321611\n",
      "Train Epoch: 1 [27000/240000 (11%)]\tLoss: 0.236916\n",
      "Train Epoch: 1 [28000/240000 (12%)]\tLoss: 0.401508\n",
      "Train Epoch: 1 [29000/240000 (12%)]\tLoss: 0.172451\n",
      "Train Epoch: 1 [30000/240000 (12%)]\tLoss: 0.400730\n",
      "Train Epoch: 1 [31000/240000 (13%)]\tLoss: 0.191270\n",
      "Train Epoch: 1 [32000/240000 (13%)]\tLoss: 0.395186\n",
      "Train Epoch: 1 [33000/240000 (14%)]\tLoss: 0.219226\n",
      "Train Epoch: 1 [34000/240000 (14%)]\tLoss: 0.237393\n",
      "Train Epoch: 1 [35000/240000 (15%)]\tLoss: 0.362168\n",
      "Train Epoch: 1 [36000/240000 (15%)]\tLoss: 0.345077\n",
      "Train Epoch: 1 [37000/240000 (15%)]\tLoss: 0.450181\n",
      "Train Epoch: 1 [38000/240000 (16%)]\tLoss: 0.199677\n",
      "Train Epoch: 1 [39000/240000 (16%)]\tLoss: 0.229559\n",
      "Train Epoch: 1 [40000/240000 (17%)]\tLoss: 0.319293\n",
      "Train Epoch: 1 [41000/240000 (17%)]\tLoss: 0.205447\n",
      "Train Epoch: 1 [42000/240000 (18%)]\tLoss: 0.252707\n",
      "Train Epoch: 1 [43000/240000 (18%)]\tLoss: 0.256178\n",
      "Train Epoch: 1 [44000/240000 (18%)]\tLoss: 0.350158\n",
      "Train Epoch: 1 [45000/240000 (19%)]\tLoss: 0.237033\n",
      "Train Epoch: 1 [46000/240000 (19%)]\tLoss: 0.187467\n",
      "Train Epoch: 1 [47000/240000 (20%)]\tLoss: 0.249303\n",
      "Train Epoch: 1 [48000/240000 (20%)]\tLoss: 0.301734\n",
      "Train Epoch: 1 [49000/240000 (20%)]\tLoss: 0.355278\n",
      "Train Epoch: 1 [50000/240000 (21%)]\tLoss: 0.258899\n",
      "Train Epoch: 1 [51000/240000 (21%)]\tLoss: 0.240242\n",
      "Train Epoch: 1 [52000/240000 (22%)]\tLoss: 0.263835\n",
      "Train Epoch: 1 [53000/240000 (22%)]\tLoss: 0.269409\n",
      "Train Epoch: 1 [54000/240000 (22%)]\tLoss: 0.274978\n",
      "Train Epoch: 1 [55000/240000 (23%)]\tLoss: 0.254883\n",
      "Train Epoch: 1 [56000/240000 (23%)]\tLoss: 0.357444\n",
      "Train Epoch: 1 [57000/240000 (24%)]\tLoss: 0.164446\n",
      "Train Epoch: 1 [58000/240000 (24%)]\tLoss: 0.584034\n",
      "Train Epoch: 1 [59000/240000 (25%)]\tLoss: 0.381160\n",
      "Train Epoch: 1 [60000/240000 (25%)]\tLoss: 0.341092\n",
      "Train Epoch: 1 [61000/240000 (25%)]\tLoss: 0.228878\n",
      "Train Epoch: 1 [62000/240000 (26%)]\tLoss: 0.387897\n",
      "Train Epoch: 1 [63000/240000 (26%)]\tLoss: 0.258264\n",
      "Train Epoch: 1 [64000/240000 (27%)]\tLoss: 0.206641\n",
      "Train Epoch: 1 [65000/240000 (27%)]\tLoss: 0.193293\n",
      "Train Epoch: 1 [66000/240000 (28%)]\tLoss: 0.375174\n",
      "Train Epoch: 1 [67000/240000 (28%)]\tLoss: 0.381050\n",
      "Train Epoch: 1 [68000/240000 (28%)]\tLoss: 0.304810\n",
      "Train Epoch: 1 [69000/240000 (29%)]\tLoss: 0.400278\n",
      "Train Epoch: 1 [70000/240000 (29%)]\tLoss: 0.230794\n",
      "Train Epoch: 1 [71000/240000 (30%)]\tLoss: 0.284418\n",
      "Train Epoch: 1 [72000/240000 (30%)]\tLoss: 0.221976\n",
      "Train Epoch: 1 [73000/240000 (30%)]\tLoss: 0.255327\n",
      "Train Epoch: 1 [74000/240000 (31%)]\tLoss: 0.313181\n",
      "Train Epoch: 1 [75000/240000 (31%)]\tLoss: 0.262565\n",
      "Train Epoch: 1 [76000/240000 (32%)]\tLoss: 0.324992\n",
      "Train Epoch: 1 [77000/240000 (32%)]\tLoss: 0.243308\n",
      "Train Epoch: 1 [78000/240000 (32%)]\tLoss: 0.490723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [79000/240000 (33%)]\tLoss: 0.269577\n",
      "Train Epoch: 1 [80000/240000 (33%)]\tLoss: 0.229056\n",
      "Train Epoch: 1 [81000/240000 (34%)]\tLoss: 0.331688\n",
      "Train Epoch: 1 [82000/240000 (34%)]\tLoss: 0.281298\n",
      "Train Epoch: 1 [83000/240000 (35%)]\tLoss: 0.183506\n",
      "Train Epoch: 1 [84000/240000 (35%)]\tLoss: 0.349800\n",
      "Train Epoch: 1 [85000/240000 (35%)]\tLoss: 0.370265\n",
      "Train Epoch: 1 [86000/240000 (36%)]\tLoss: 0.339845\n",
      "Train Epoch: 1 [87000/240000 (36%)]\tLoss: 0.329440\n",
      "Train Epoch: 1 [88000/240000 (37%)]\tLoss: 0.262579\n",
      "Train Epoch: 1 [89000/240000 (37%)]\tLoss: 0.383266\n",
      "Train Epoch: 1 [90000/240000 (38%)]\tLoss: 0.285419\n",
      "Train Epoch: 1 [91000/240000 (38%)]\tLoss: 0.352432\n",
      "Train Epoch: 1 [92000/240000 (38%)]\tLoss: 0.147437\n",
      "Train Epoch: 1 [93000/240000 (39%)]\tLoss: 0.268880\n",
      "Train Epoch: 1 [94000/240000 (39%)]\tLoss: 0.320653\n",
      "Train Epoch: 1 [95000/240000 (40%)]\tLoss: 0.288817\n",
      "Train Epoch: 1 [96000/240000 (40%)]\tLoss: 0.268708\n",
      "Train Epoch: 1 [97000/240000 (40%)]\tLoss: 0.322842\n",
      "Train Epoch: 1 [98000/240000 (41%)]\tLoss: 0.294469\n",
      "Train Epoch: 1 [99000/240000 (41%)]\tLoss: 0.224362\n",
      "Train Epoch: 1 [100000/240000 (42%)]\tLoss: 0.313495\n",
      "Train Epoch: 1 [101000/240000 (42%)]\tLoss: 0.251574\n",
      "Train Epoch: 1 [102000/240000 (42%)]\tLoss: 0.414949\n",
      "Train Epoch: 1 [103000/240000 (43%)]\tLoss: 0.310722\n",
      "Train Epoch: 1 [104000/240000 (43%)]\tLoss: 0.218840\n",
      "Train Epoch: 1 [105000/240000 (44%)]\tLoss: 0.381539\n",
      "Train Epoch: 1 [106000/240000 (44%)]\tLoss: 0.208047\n",
      "Train Epoch: 1 [107000/240000 (45%)]\tLoss: 0.345300\n",
      "Train Epoch: 1 [108000/240000 (45%)]\tLoss: 0.264378\n",
      "Train Epoch: 1 [109000/240000 (45%)]\tLoss: 0.253194\n",
      "Train Epoch: 1 [110000/240000 (46%)]\tLoss: 0.332325\n",
      "Train Epoch: 1 [111000/240000 (46%)]\tLoss: 0.251689\n",
      "Train Epoch: 1 [112000/240000 (47%)]\tLoss: 0.216716\n",
      "Train Epoch: 1 [113000/240000 (47%)]\tLoss: 0.203409\n",
      "Train Epoch: 1 [114000/240000 (48%)]\tLoss: 0.371930\n",
      "Train Epoch: 1 [115000/240000 (48%)]\tLoss: 0.225598\n",
      "Train Epoch: 1 [116000/240000 (48%)]\tLoss: 0.215297\n",
      "Train Epoch: 1 [117000/240000 (49%)]\tLoss: 0.292447\n",
      "Train Epoch: 1 [118000/240000 (49%)]\tLoss: 0.447785\n",
      "Train Epoch: 1 [119000/240000 (50%)]\tLoss: 0.203651\n",
      "Train Epoch: 1 [120000/240000 (50%)]\tLoss: 0.228449\n",
      "Train Epoch: 1 [121000/240000 (50%)]\tLoss: 0.238454\n",
      "Train Epoch: 1 [122000/240000 (51%)]\tLoss: 0.185035\n",
      "Train Epoch: 1 [123000/240000 (51%)]\tLoss: 0.225571\n",
      "Train Epoch: 1 [124000/240000 (52%)]\tLoss: 0.303535\n",
      "Train Epoch: 1 [125000/240000 (52%)]\tLoss: 0.302241\n",
      "Train Epoch: 1 [126000/240000 (52%)]\tLoss: 0.233979\n",
      "Train Epoch: 1 [127000/240000 (53%)]\tLoss: 0.239618\n",
      "Train Epoch: 1 [128000/240000 (53%)]\tLoss: 0.520866\n",
      "Train Epoch: 1 [129000/240000 (54%)]\tLoss: 0.157395\n",
      "Train Epoch: 1 [130000/240000 (54%)]\tLoss: 0.420784\n",
      "Train Epoch: 1 [131000/240000 (55%)]\tLoss: 0.300362\n",
      "Train Epoch: 1 [132000/240000 (55%)]\tLoss: 0.212172\n",
      "Train Epoch: 1 [133000/240000 (55%)]\tLoss: 0.356992\n",
      "Train Epoch: 1 [134000/240000 (56%)]\tLoss: 0.197266\n",
      "Train Epoch: 1 [135000/240000 (56%)]\tLoss: 0.241526\n",
      "Train Epoch: 1 [136000/240000 (57%)]\tLoss: 0.264008\n",
      "Train Epoch: 1 [137000/240000 (57%)]\tLoss: 0.330032\n",
      "Train Epoch: 1 [138000/240000 (58%)]\tLoss: 0.307995\n",
      "Train Epoch: 1 [139000/240000 (58%)]\tLoss: 0.337059\n",
      "Train Epoch: 1 [140000/240000 (58%)]\tLoss: 0.159164\n",
      "Train Epoch: 1 [141000/240000 (59%)]\tLoss: 0.244060\n",
      "Train Epoch: 1 [142000/240000 (59%)]\tLoss: 0.266652\n",
      "Train Epoch: 1 [143000/240000 (60%)]\tLoss: 0.322934\n",
      "Train Epoch: 1 [144000/240000 (60%)]\tLoss: 0.278749\n",
      "Train Epoch: 1 [145000/240000 (60%)]\tLoss: 0.267544\n",
      "Train Epoch: 1 [146000/240000 (61%)]\tLoss: 0.205364\n",
      "Train Epoch: 1 [147000/240000 (61%)]\tLoss: 0.180066\n",
      "Train Epoch: 1 [148000/240000 (62%)]\tLoss: 0.204221\n",
      "Train Epoch: 1 [149000/240000 (62%)]\tLoss: 0.207086\n",
      "Train Epoch: 1 [150000/240000 (62%)]\tLoss: 0.216610\n",
      "Train Epoch: 1 [151000/240000 (63%)]\tLoss: 0.385319\n",
      "Train Epoch: 1 [152000/240000 (63%)]\tLoss: 0.351368\n",
      "Train Epoch: 1 [153000/240000 (64%)]\tLoss: 0.186573\n",
      "Train Epoch: 1 [154000/240000 (64%)]\tLoss: 0.324381\n",
      "Train Epoch: 1 [155000/240000 (65%)]\tLoss: 0.164417\n",
      "Train Epoch: 1 [156000/240000 (65%)]\tLoss: 0.172187\n",
      "Train Epoch: 1 [157000/240000 (65%)]\tLoss: 0.392014\n",
      "Train Epoch: 1 [158000/240000 (66%)]\tLoss: 0.286493\n",
      "Train Epoch: 1 [159000/240000 (66%)]\tLoss: 0.308573\n",
      "Train Epoch: 1 [160000/240000 (67%)]\tLoss: 0.246388\n",
      "Train Epoch: 1 [161000/240000 (67%)]\tLoss: 0.108777\n",
      "Train Epoch: 1 [162000/240000 (68%)]\tLoss: 0.271845\n",
      "Train Epoch: 1 [163000/240000 (68%)]\tLoss: 0.229675\n",
      "Train Epoch: 1 [164000/240000 (68%)]\tLoss: 0.253334\n",
      "Train Epoch: 1 [165000/240000 (69%)]\tLoss: 0.324871\n",
      "Train Epoch: 1 [166000/240000 (69%)]\tLoss: 0.210129\n",
      "Train Epoch: 1 [167000/240000 (70%)]\tLoss: 0.240097\n",
      "Train Epoch: 1 [168000/240000 (70%)]\tLoss: 0.327643\n",
      "Train Epoch: 1 [169000/240000 (70%)]\tLoss: 0.193841\n",
      "Train Epoch: 1 [170000/240000 (71%)]\tLoss: 0.330456\n",
      "Train Epoch: 1 [171000/240000 (71%)]\tLoss: 0.518184\n",
      "Train Epoch: 1 [172000/240000 (72%)]\tLoss: 0.239429\n",
      "Train Epoch: 1 [173000/240000 (72%)]\tLoss: 0.216594\n",
      "Train Epoch: 1 [174000/240000 (72%)]\tLoss: 0.267527\n",
      "Train Epoch: 1 [175000/240000 (73%)]\tLoss: 0.210951\n",
      "Train Epoch: 1 [176000/240000 (73%)]\tLoss: 0.205137\n",
      "Train Epoch: 1 [177000/240000 (74%)]\tLoss: 0.197571\n",
      "Train Epoch: 1 [178000/240000 (74%)]\tLoss: 0.311065\n",
      "Train Epoch: 1 [179000/240000 (75%)]\tLoss: 0.274089\n",
      "Train Epoch: 1 [180000/240000 (75%)]\tLoss: 0.197284\n",
      "Train Epoch: 1 [181000/240000 (75%)]\tLoss: 0.172475\n",
      "Train Epoch: 1 [182000/240000 (76%)]\tLoss: 0.189746\n",
      "Train Epoch: 1 [183000/240000 (76%)]\tLoss: 0.172409\n",
      "Train Epoch: 1 [184000/240000 (77%)]\tLoss: 0.225081\n",
      "Train Epoch: 1 [185000/240000 (77%)]\tLoss: 0.366366\n",
      "Train Epoch: 1 [186000/240000 (78%)]\tLoss: 0.274819\n",
      "Train Epoch: 1 [187000/240000 (78%)]\tLoss: 0.226016\n",
      "Train Epoch: 1 [188000/240000 (78%)]\tLoss: 0.230651\n",
      "Train Epoch: 1 [189000/240000 (79%)]\tLoss: 0.337528\n",
      "Train Epoch: 1 [190000/240000 (79%)]\tLoss: 0.279091\n",
      "Train Epoch: 1 [191000/240000 (80%)]\tLoss: 0.239886\n",
      "Train Epoch: 1 [192000/240000 (80%)]\tLoss: 0.195731\n",
      "Train Epoch: 1 [193000/240000 (80%)]\tLoss: 0.337319\n",
      "Train Epoch: 1 [194000/240000 (81%)]\tLoss: 0.250582\n",
      "Train Epoch: 1 [195000/240000 (81%)]\tLoss: 0.310336\n",
      "Train Epoch: 1 [196000/240000 (82%)]\tLoss: 0.325112\n",
      "Train Epoch: 1 [197000/240000 (82%)]\tLoss: 0.185227\n",
      "Train Epoch: 1 [198000/240000 (82%)]\tLoss: 0.412400\n",
      "Train Epoch: 1 [199000/240000 (83%)]\tLoss: 0.220180\n",
      "Train Epoch: 1 [200000/240000 (83%)]\tLoss: 0.134135\n",
      "Train Epoch: 1 [201000/240000 (84%)]\tLoss: 0.309356\n",
      "Train Epoch: 1 [202000/240000 (84%)]\tLoss: 0.150720\n",
      "Train Epoch: 1 [203000/240000 (85%)]\tLoss: 0.215409\n",
      "Train Epoch: 1 [204000/240000 (85%)]\tLoss: 0.228376\n",
      "Train Epoch: 1 [205000/240000 (85%)]\tLoss: 0.201910\n",
      "Train Epoch: 1 [206000/240000 (86%)]\tLoss: 0.209237\n",
      "Train Epoch: 1 [207000/240000 (86%)]\tLoss: 0.191091\n",
      "Train Epoch: 1 [208000/240000 (87%)]\tLoss: 0.297196\n",
      "Train Epoch: 1 [209000/240000 (87%)]\tLoss: 0.308085\n",
      "Train Epoch: 1 [210000/240000 (88%)]\tLoss: 0.197622\n",
      "Train Epoch: 1 [211000/240000 (88%)]\tLoss: 0.336896\n",
      "Train Epoch: 1 [212000/240000 (88%)]\tLoss: 0.116588\n",
      "Train Epoch: 1 [213000/240000 (89%)]\tLoss: 0.272200\n",
      "Train Epoch: 1 [214000/240000 (89%)]\tLoss: 0.151399\n",
      "Train Epoch: 1 [215000/240000 (90%)]\tLoss: 0.172841\n",
      "Train Epoch: 1 [216000/240000 (90%)]\tLoss: 0.262616\n",
      "Train Epoch: 1 [217000/240000 (90%)]\tLoss: 0.242048\n",
      "Train Epoch: 1 [218000/240000 (91%)]\tLoss: 0.157289\n",
      "Train Epoch: 1 [219000/240000 (91%)]\tLoss: 0.261185\n",
      "Train Epoch: 1 [220000/240000 (92%)]\tLoss: 0.172303\n",
      "Train Epoch: 1 [221000/240000 (92%)]\tLoss: 0.220051\n",
      "Train Epoch: 1 [222000/240000 (92%)]\tLoss: 0.105303\n",
      "Train Epoch: 1 [223000/240000 (93%)]\tLoss: 0.248144\n",
      "Train Epoch: 1 [224000/240000 (93%)]\tLoss: 0.235347\n",
      "Train Epoch: 1 [225000/240000 (94%)]\tLoss: 0.240242\n",
      "Train Epoch: 1 [226000/240000 (94%)]\tLoss: 0.190209\n",
      "Train Epoch: 1 [227000/240000 (95%)]\tLoss: 0.398694\n",
      "Train Epoch: 1 [228000/240000 (95%)]\tLoss: 0.231562\n",
      "Train Epoch: 1 [229000/240000 (95%)]\tLoss: 0.291832\n",
      "Train Epoch: 1 [230000/240000 (96%)]\tLoss: 0.218381\n",
      "Train Epoch: 1 [231000/240000 (96%)]\tLoss: 0.269791\n",
      "Train Epoch: 1 [232000/240000 (97%)]\tLoss: 0.271017\n",
      "Train Epoch: 1 [233000/240000 (97%)]\tLoss: 0.199267\n",
      "Train Epoch: 1 [234000/240000 (98%)]\tLoss: 0.446677\n",
      "Train Epoch: 1 [235000/240000 (98%)]\tLoss: 0.375791\n",
      "Train Epoch: 1 [236000/240000 (98%)]\tLoss: 0.307129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [237000/240000 (99%)]\tLoss: 0.207882\n",
      "Train Epoch: 1 [238000/240000 (99%)]\tLoss: 0.224160\n",
      "Train Epoch: 1 [239000/240000 (100%)]\tLoss: 0.181795\n",
      "Time elapsed 0:02:16.062551\n",
      "\n",
      "Test set: Average loss: 0.1855, Accuracy: 37829.0/40000 (95%)\n",
      "\n",
      "2 of 5 100 0.2\n",
      "Train Epoch: 2 [0/240000 (0%)]\tLoss: 0.273974\n",
      "Train Epoch: 2 [1000/240000 (0%)]\tLoss: 0.251346\n",
      "Train Epoch: 2 [2000/240000 (1%)]\tLoss: 0.398891\n",
      "Train Epoch: 2 [3000/240000 (1%)]\tLoss: 0.205944\n",
      "Train Epoch: 2 [4000/240000 (2%)]\tLoss: 0.161256\n",
      "Train Epoch: 2 [5000/240000 (2%)]\tLoss: 0.307327\n",
      "Train Epoch: 2 [6000/240000 (2%)]\tLoss: 0.271132\n",
      "Train Epoch: 2 [7000/240000 (3%)]\tLoss: 0.190424\n",
      "Train Epoch: 2 [8000/240000 (3%)]\tLoss: 0.224916\n",
      "Train Epoch: 2 [9000/240000 (4%)]\tLoss: 0.147158\n",
      "Train Epoch: 2 [10000/240000 (4%)]\tLoss: 0.250024\n",
      "Train Epoch: 2 [11000/240000 (5%)]\tLoss: 0.269586\n",
      "Train Epoch: 2 [12000/240000 (5%)]\tLoss: 0.174083\n",
      "Train Epoch: 2 [13000/240000 (5%)]\tLoss: 0.215314\n",
      "Train Epoch: 2 [14000/240000 (6%)]\tLoss: 0.183901\n",
      "Train Epoch: 2 [15000/240000 (6%)]\tLoss: 0.305716\n",
      "Train Epoch: 2 [16000/240000 (7%)]\tLoss: 0.272011\n",
      "Train Epoch: 2 [17000/240000 (7%)]\tLoss: 0.232557\n",
      "Train Epoch: 2 [18000/240000 (8%)]\tLoss: 0.161705\n",
      "Train Epoch: 2 [19000/240000 (8%)]\tLoss: 0.258707\n",
      "Train Epoch: 2 [20000/240000 (8%)]\tLoss: 0.170331\n",
      "Train Epoch: 2 [21000/240000 (9%)]\tLoss: 0.170461\n",
      "Train Epoch: 2 [22000/240000 (9%)]\tLoss: 0.224429\n",
      "Train Epoch: 2 [23000/240000 (10%)]\tLoss: 0.216332\n",
      "Train Epoch: 2 [24000/240000 (10%)]\tLoss: 0.364237\n",
      "Train Epoch: 2 [25000/240000 (10%)]\tLoss: 0.249798\n",
      "Train Epoch: 2 [26000/240000 (11%)]\tLoss: 0.205708\n",
      "Train Epoch: 2 [27000/240000 (11%)]\tLoss: 0.235430\n",
      "Train Epoch: 2 [28000/240000 (12%)]\tLoss: 0.150866\n",
      "Train Epoch: 2 [29000/240000 (12%)]\tLoss: 0.276753\n",
      "Train Epoch: 2 [30000/240000 (12%)]\tLoss: 0.128853\n",
      "Train Epoch: 2 [31000/240000 (13%)]\tLoss: 0.311314\n",
      "Train Epoch: 2 [32000/240000 (13%)]\tLoss: 0.356247\n",
      "Train Epoch: 2 [33000/240000 (14%)]\tLoss: 0.375151\n",
      "Train Epoch: 2 [34000/240000 (14%)]\tLoss: 0.172203\n",
      "Train Epoch: 2 [35000/240000 (15%)]\tLoss: 0.425842\n",
      "Train Epoch: 2 [36000/240000 (15%)]\tLoss: 0.218967\n",
      "Train Epoch: 2 [37000/240000 (15%)]\tLoss: 0.243409\n",
      "Train Epoch: 2 [38000/240000 (16%)]\tLoss: 0.232161\n",
      "Train Epoch: 2 [39000/240000 (16%)]\tLoss: 0.269950\n",
      "Train Epoch: 2 [40000/240000 (17%)]\tLoss: 0.151720\n",
      "Train Epoch: 2 [41000/240000 (17%)]\tLoss: 0.248929\n",
      "Train Epoch: 2 [42000/240000 (18%)]\tLoss: 0.139840\n",
      "Train Epoch: 2 [43000/240000 (18%)]\tLoss: 0.206075\n",
      "Train Epoch: 2 [44000/240000 (18%)]\tLoss: 0.393728\n",
      "Train Epoch: 2 [45000/240000 (19%)]\tLoss: 0.294476\n",
      "Train Epoch: 2 [46000/240000 (19%)]\tLoss: 0.237045\n",
      "Train Epoch: 2 [47000/240000 (20%)]\tLoss: 0.182252\n",
      "Train Epoch: 2 [48000/240000 (20%)]\tLoss: 0.114655\n",
      "Train Epoch: 2 [49000/240000 (20%)]\tLoss: 0.135736\n",
      "Train Epoch: 2 [50000/240000 (21%)]\tLoss: 0.205445\n",
      "Train Epoch: 2 [51000/240000 (21%)]\tLoss: 0.390296\n",
      "Train Epoch: 2 [52000/240000 (22%)]\tLoss: 0.169280\n",
      "Train Epoch: 2 [53000/240000 (22%)]\tLoss: 0.187566\n",
      "Train Epoch: 2 [54000/240000 (22%)]\tLoss: 0.264492\n",
      "Train Epoch: 2 [55000/240000 (23%)]\tLoss: 0.233271\n",
      "Train Epoch: 2 [56000/240000 (23%)]\tLoss: 0.254475\n",
      "Train Epoch: 2 [57000/240000 (24%)]\tLoss: 0.263648\n",
      "Train Epoch: 2 [58000/240000 (24%)]\tLoss: 0.170077\n",
      "Train Epoch: 2 [59000/240000 (25%)]\tLoss: 0.156649\n",
      "Train Epoch: 2 [60000/240000 (25%)]\tLoss: 0.235598\n",
      "Train Epoch: 2 [61000/240000 (25%)]\tLoss: 0.170229\n",
      "Train Epoch: 2 [62000/240000 (26%)]\tLoss: 0.213768\n",
      "Train Epoch: 2 [63000/240000 (26%)]\tLoss: 0.097001\n",
      "Train Epoch: 2 [64000/240000 (27%)]\tLoss: 0.292964\n",
      "Train Epoch: 2 [65000/240000 (27%)]\tLoss: 0.193296\n",
      "Train Epoch: 2 [66000/240000 (28%)]\tLoss: 0.248700\n",
      "Train Epoch: 2 [67000/240000 (28%)]\tLoss: 0.228883\n",
      "Train Epoch: 2 [68000/240000 (28%)]\tLoss: 0.362408\n",
      "Train Epoch: 2 [69000/240000 (29%)]\tLoss: 0.144994\n",
      "Train Epoch: 2 [70000/240000 (29%)]\tLoss: 0.077266\n",
      "Train Epoch: 2 [71000/240000 (30%)]\tLoss: 0.137793\n",
      "Train Epoch: 2 [72000/240000 (30%)]\tLoss: 0.288456\n",
      "Train Epoch: 2 [73000/240000 (30%)]\tLoss: 0.169157\n",
      "Train Epoch: 2 [74000/240000 (31%)]\tLoss: 0.289943\n",
      "Train Epoch: 2 [75000/240000 (31%)]\tLoss: 0.194572\n",
      "Train Epoch: 2 [76000/240000 (32%)]\tLoss: 0.274975\n",
      "Train Epoch: 2 [77000/240000 (32%)]\tLoss: 0.193475\n",
      "Train Epoch: 2 [78000/240000 (32%)]\tLoss: 0.248457\n",
      "Train Epoch: 2 [79000/240000 (33%)]\tLoss: 0.198530\n",
      "Train Epoch: 2 [80000/240000 (33%)]\tLoss: 0.349048\n",
      "Train Epoch: 2 [81000/240000 (34%)]\tLoss: 0.218489\n",
      "Train Epoch: 2 [82000/240000 (34%)]\tLoss: 0.168877\n",
      "Train Epoch: 2 [83000/240000 (35%)]\tLoss: 0.269252\n",
      "Train Epoch: 2 [84000/240000 (35%)]\tLoss: 0.177846\n",
      "Train Epoch: 2 [85000/240000 (35%)]\tLoss: 0.376765\n",
      "Train Epoch: 2 [86000/240000 (36%)]\tLoss: 0.297611\n",
      "Train Epoch: 2 [87000/240000 (36%)]\tLoss: 0.238192\n",
      "Train Epoch: 2 [88000/240000 (37%)]\tLoss: 0.154354\n",
      "Train Epoch: 2 [89000/240000 (37%)]\tLoss: 0.128091\n",
      "Train Epoch: 2 [90000/240000 (38%)]\tLoss: 0.311698\n",
      "Train Epoch: 2 [91000/240000 (38%)]\tLoss: 0.135089\n",
      "Train Epoch: 2 [92000/240000 (38%)]\tLoss: 0.163251\n",
      "Train Epoch: 2 [93000/240000 (39%)]\tLoss: 0.469729\n",
      "Train Epoch: 2 [94000/240000 (39%)]\tLoss: 0.321419\n",
      "Train Epoch: 2 [95000/240000 (40%)]\tLoss: 0.269035\n",
      "Train Epoch: 2 [96000/240000 (40%)]\tLoss: 0.285891\n",
      "Train Epoch: 2 [97000/240000 (40%)]\tLoss: 0.147283\n",
      "Train Epoch: 2 [98000/240000 (41%)]\tLoss: 0.280081\n",
      "Train Epoch: 2 [99000/240000 (41%)]\tLoss: 0.195067\n",
      "Train Epoch: 2 [100000/240000 (42%)]\tLoss: 0.316002\n",
      "Train Epoch: 2 [101000/240000 (42%)]\tLoss: 0.169157\n",
      "Train Epoch: 2 [102000/240000 (42%)]\tLoss: 0.248278\n",
      "Train Epoch: 2 [103000/240000 (43%)]\tLoss: 0.156967\n",
      "Train Epoch: 2 [104000/240000 (43%)]\tLoss: 0.226000\n",
      "Train Epoch: 2 [105000/240000 (44%)]\tLoss: 0.125777\n",
      "Train Epoch: 2 [106000/240000 (44%)]\tLoss: 0.131233\n",
      "Train Epoch: 2 [107000/240000 (45%)]\tLoss: 0.177884\n",
      "Train Epoch: 2 [108000/240000 (45%)]\tLoss: 0.216332\n",
      "Train Epoch: 2 [109000/240000 (45%)]\tLoss: 0.345560\n",
      "Train Epoch: 2 [110000/240000 (46%)]\tLoss: 0.271860\n",
      "Train Epoch: 2 [111000/240000 (46%)]\tLoss: 0.196557\n",
      "Train Epoch: 2 [112000/240000 (47%)]\tLoss: 0.117548\n",
      "Train Epoch: 2 [113000/240000 (47%)]\tLoss: 0.175035\n",
      "Train Epoch: 2 [114000/240000 (48%)]\tLoss: 0.258791\n",
      "Train Epoch: 2 [115000/240000 (48%)]\tLoss: 0.197744\n",
      "Train Epoch: 2 [116000/240000 (48%)]\tLoss: 0.178171\n",
      "Train Epoch: 2 [117000/240000 (49%)]\tLoss: 0.228545\n",
      "Train Epoch: 2 [118000/240000 (49%)]\tLoss: 0.237902\n",
      "Train Epoch: 2 [119000/240000 (50%)]\tLoss: 0.172687\n",
      "Train Epoch: 2 [120000/240000 (50%)]\tLoss: 0.147041\n",
      "Train Epoch: 2 [121000/240000 (50%)]\tLoss: 0.255073\n",
      "Train Epoch: 2 [122000/240000 (51%)]\tLoss: 0.157595\n",
      "Train Epoch: 2 [123000/240000 (51%)]\tLoss: 0.173883\n",
      "Train Epoch: 2 [124000/240000 (52%)]\tLoss: 0.224586\n",
      "Train Epoch: 2 [125000/240000 (52%)]\tLoss: 0.164942\n",
      "Train Epoch: 2 [126000/240000 (52%)]\tLoss: 0.121047\n",
      "Train Epoch: 2 [127000/240000 (53%)]\tLoss: 0.160234\n",
      "Train Epoch: 2 [128000/240000 (53%)]\tLoss: 0.220685\n",
      "Train Epoch: 2 [129000/240000 (54%)]\tLoss: 0.260994\n",
      "Train Epoch: 2 [130000/240000 (54%)]\tLoss: 0.310624\n",
      "Train Epoch: 2 [131000/240000 (55%)]\tLoss: 0.177781\n",
      "Train Epoch: 2 [132000/240000 (55%)]\tLoss: 0.174798\n",
      "Train Epoch: 2 [133000/240000 (55%)]\tLoss: 0.153374\n",
      "Train Epoch: 2 [134000/240000 (56%)]\tLoss: 0.189482\n",
      "Train Epoch: 2 [135000/240000 (56%)]\tLoss: 0.132218\n",
      "Train Epoch: 2 [136000/240000 (57%)]\tLoss: 0.329706\n",
      "Train Epoch: 2 [137000/240000 (57%)]\tLoss: 0.119965\n",
      "Train Epoch: 2 [138000/240000 (58%)]\tLoss: 0.109190\n",
      "Train Epoch: 2 [139000/240000 (58%)]\tLoss: 0.215762\n",
      "Train Epoch: 2 [140000/240000 (58%)]\tLoss: 0.123667\n",
      "Train Epoch: 2 [141000/240000 (59%)]\tLoss: 0.304776\n",
      "Train Epoch: 2 [142000/240000 (59%)]\tLoss: 0.192189\n",
      "Train Epoch: 2 [143000/240000 (60%)]\tLoss: 0.110977\n",
      "Train Epoch: 2 [144000/240000 (60%)]\tLoss: 0.289730\n",
      "Train Epoch: 2 [145000/240000 (60%)]\tLoss: 0.121842\n",
      "Train Epoch: 2 [146000/240000 (61%)]\tLoss: 0.127122\n",
      "Train Epoch: 2 [147000/240000 (61%)]\tLoss: 0.296185\n",
      "Train Epoch: 2 [148000/240000 (62%)]\tLoss: 0.114573\n",
      "Train Epoch: 2 [149000/240000 (62%)]\tLoss: 0.261008\n",
      "Train Epoch: 2 [150000/240000 (62%)]\tLoss: 0.169897\n",
      "Train Epoch: 2 [151000/240000 (63%)]\tLoss: 0.159824\n",
      "Train Epoch: 2 [152000/240000 (63%)]\tLoss: 0.254468\n",
      "Train Epoch: 2 [153000/240000 (64%)]\tLoss: 0.292507\n",
      "Train Epoch: 2 [154000/240000 (64%)]\tLoss: 0.177238\n",
      "Train Epoch: 2 [155000/240000 (65%)]\tLoss: 0.301926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [156000/240000 (65%)]\tLoss: 0.126808\n",
      "Train Epoch: 2 [157000/240000 (65%)]\tLoss: 0.374471\n",
      "Train Epoch: 2 [158000/240000 (66%)]\tLoss: 0.192327\n",
      "Train Epoch: 2 [159000/240000 (66%)]\tLoss: 0.155754\n",
      "Train Epoch: 2 [160000/240000 (67%)]\tLoss: 0.219010\n",
      "Train Epoch: 2 [161000/240000 (67%)]\tLoss: 0.262983\n",
      "Train Epoch: 2 [162000/240000 (68%)]\tLoss: 0.267832\n",
      "Train Epoch: 2 [163000/240000 (68%)]\tLoss: 0.207433\n",
      "Train Epoch: 2 [164000/240000 (68%)]\tLoss: 0.198118\n",
      "Train Epoch: 2 [165000/240000 (69%)]\tLoss: 0.230352\n",
      "Train Epoch: 2 [166000/240000 (69%)]\tLoss: 0.180886\n",
      "Train Epoch: 2 [167000/240000 (70%)]\tLoss: 0.225197\n",
      "Train Epoch: 2 [168000/240000 (70%)]\tLoss: 0.174864\n",
      "Train Epoch: 2 [169000/240000 (70%)]\tLoss: 0.123304\n",
      "Train Epoch: 2 [170000/240000 (71%)]\tLoss: 0.246125\n",
      "Train Epoch: 2 [171000/240000 (71%)]\tLoss: 0.280024\n",
      "Train Epoch: 2 [172000/240000 (72%)]\tLoss: 0.291746\n",
      "Train Epoch: 2 [173000/240000 (72%)]\tLoss: 0.161439\n",
      "Train Epoch: 2 [174000/240000 (72%)]\tLoss: 0.216568\n",
      "Train Epoch: 2 [175000/240000 (73%)]\tLoss: 0.180622\n",
      "Train Epoch: 2 [176000/240000 (73%)]\tLoss: 0.245591\n",
      "Train Epoch: 2 [177000/240000 (74%)]\tLoss: 0.320564\n",
      "Train Epoch: 2 [178000/240000 (74%)]\tLoss: 0.144224\n",
      "Train Epoch: 2 [179000/240000 (75%)]\tLoss: 0.105758\n",
      "Train Epoch: 2 [180000/240000 (75%)]\tLoss: 0.215186\n",
      "Train Epoch: 2 [181000/240000 (75%)]\tLoss: 0.210266\n",
      "Train Epoch: 2 [182000/240000 (76%)]\tLoss: 0.136900\n",
      "Train Epoch: 2 [183000/240000 (76%)]\tLoss: 0.194512\n",
      "Train Epoch: 2 [184000/240000 (77%)]\tLoss: 0.147162\n",
      "Train Epoch: 2 [185000/240000 (77%)]\tLoss: 0.153050\n",
      "Train Epoch: 2 [186000/240000 (78%)]\tLoss: 0.218168\n",
      "Train Epoch: 2 [187000/240000 (78%)]\tLoss: 0.241983\n",
      "Train Epoch: 2 [188000/240000 (78%)]\tLoss: 0.170344\n",
      "Train Epoch: 2 [189000/240000 (79%)]\tLoss: 0.187622\n",
      "Train Epoch: 2 [190000/240000 (79%)]\tLoss: 0.345544\n",
      "Train Epoch: 2 [191000/240000 (80%)]\tLoss: 0.175770\n",
      "Train Epoch: 2 [192000/240000 (80%)]\tLoss: 0.132676\n",
      "Train Epoch: 2 [193000/240000 (80%)]\tLoss: 0.193737\n",
      "Train Epoch: 2 [194000/240000 (81%)]\tLoss: 0.201634\n",
      "Train Epoch: 2 [195000/240000 (81%)]\tLoss: 0.291887\n",
      "Train Epoch: 2 [196000/240000 (82%)]\tLoss: 0.154070\n",
      "Train Epoch: 2 [197000/240000 (82%)]\tLoss: 0.253244\n",
      "Train Epoch: 2 [198000/240000 (82%)]\tLoss: 0.198591\n",
      "Train Epoch: 2 [199000/240000 (83%)]\tLoss: 0.171692\n",
      "Train Epoch: 2 [200000/240000 (83%)]\tLoss: 0.220707\n",
      "Train Epoch: 2 [201000/240000 (84%)]\tLoss: 0.092269\n",
      "Train Epoch: 2 [202000/240000 (84%)]\tLoss: 0.352262\n",
      "Train Epoch: 2 [203000/240000 (85%)]\tLoss: 0.181217\n",
      "Train Epoch: 2 [204000/240000 (85%)]\tLoss: 0.293386\n",
      "Train Epoch: 2 [205000/240000 (85%)]\tLoss: 0.214867\n",
      "Train Epoch: 2 [206000/240000 (86%)]\tLoss: 0.155737\n",
      "Train Epoch: 2 [207000/240000 (86%)]\tLoss: 0.120164\n",
      "Train Epoch: 2 [208000/240000 (87%)]\tLoss: 0.127120\n",
      "Train Epoch: 2 [209000/240000 (87%)]\tLoss: 0.171847\n",
      "Train Epoch: 2 [210000/240000 (88%)]\tLoss: 0.223461\n",
      "Train Epoch: 2 [211000/240000 (88%)]\tLoss: 0.190622\n",
      "Train Epoch: 2 [212000/240000 (88%)]\tLoss: 0.218669\n",
      "Train Epoch: 2 [213000/240000 (89%)]\tLoss: 0.112200\n",
      "Train Epoch: 2 [214000/240000 (89%)]\tLoss: 0.203589\n",
      "Train Epoch: 2 [215000/240000 (90%)]\tLoss: 0.224746\n",
      "Train Epoch: 2 [216000/240000 (90%)]\tLoss: 0.126513\n",
      "Train Epoch: 2 [217000/240000 (90%)]\tLoss: 0.255873\n",
      "Train Epoch: 2 [218000/240000 (91%)]\tLoss: 0.220306\n",
      "Train Epoch: 2 [219000/240000 (91%)]\tLoss: 0.139092\n",
      "Train Epoch: 2 [220000/240000 (92%)]\tLoss: 0.322456\n",
      "Train Epoch: 2 [221000/240000 (92%)]\tLoss: 0.208683\n",
      "Train Epoch: 2 [222000/240000 (92%)]\tLoss: 0.220814\n",
      "Train Epoch: 2 [223000/240000 (93%)]\tLoss: 0.152251\n",
      "Train Epoch: 2 [224000/240000 (93%)]\tLoss: 0.143350\n",
      "Train Epoch: 2 [225000/240000 (94%)]\tLoss: 0.255570\n",
      "Train Epoch: 2 [226000/240000 (94%)]\tLoss: 0.316387\n",
      "Train Epoch: 2 [227000/240000 (95%)]\tLoss: 0.264622\n",
      "Train Epoch: 2 [228000/240000 (95%)]\tLoss: 0.152928\n",
      "Train Epoch: 2 [229000/240000 (95%)]\tLoss: 0.132660\n",
      "Train Epoch: 2 [230000/240000 (96%)]\tLoss: 0.163407\n",
      "Train Epoch: 2 [231000/240000 (96%)]\tLoss: 0.233644\n",
      "Train Epoch: 2 [232000/240000 (97%)]\tLoss: 0.194024\n",
      "Train Epoch: 2 [233000/240000 (97%)]\tLoss: 0.118994\n",
      "Train Epoch: 2 [234000/240000 (98%)]\tLoss: 0.133810\n",
      "Train Epoch: 2 [235000/240000 (98%)]\tLoss: 0.128695\n",
      "Train Epoch: 2 [236000/240000 (98%)]\tLoss: 0.177287\n",
      "Train Epoch: 2 [237000/240000 (99%)]\tLoss: 0.155044\n",
      "Train Epoch: 2 [238000/240000 (99%)]\tLoss: 0.248215\n",
      "Train Epoch: 2 [239000/240000 (100%)]\tLoss: 0.214660\n",
      "Time elapsed 0:03:28.677746\n",
      "\n",
      "Test set: Average loss: 0.1515, Accuracy: 38226.0/40000 (96%)\n",
      "\n",
      "3 of 5 100 0.2\n",
      "Train Epoch: 3 [0/240000 (0%)]\tLoss: 0.098503\n",
      "Train Epoch: 3 [1000/240000 (0%)]\tLoss: 0.188830\n",
      "Train Epoch: 3 [2000/240000 (1%)]\tLoss: 0.265031\n",
      "Train Epoch: 3 [3000/240000 (1%)]\tLoss: 0.238020\n",
      "Train Epoch: 3 [4000/240000 (2%)]\tLoss: 0.233074\n",
      "Train Epoch: 3 [5000/240000 (2%)]\tLoss: 0.152962\n",
      "Train Epoch: 3 [6000/240000 (2%)]\tLoss: 0.178059\n",
      "Train Epoch: 3 [7000/240000 (3%)]\tLoss: 0.325165\n",
      "Train Epoch: 3 [8000/240000 (3%)]\tLoss: 0.129636\n",
      "Train Epoch: 3 [9000/240000 (4%)]\tLoss: 0.308480\n",
      "Train Epoch: 3 [10000/240000 (4%)]\tLoss: 0.167859\n",
      "Train Epoch: 3 [11000/240000 (5%)]\tLoss: 0.352313\n",
      "Train Epoch: 3 [12000/240000 (5%)]\tLoss: 0.195951\n",
      "Train Epoch: 3 [13000/240000 (5%)]\tLoss: 0.173693\n",
      "Train Epoch: 3 [14000/240000 (6%)]\tLoss: 0.159270\n",
      "Train Epoch: 3 [15000/240000 (6%)]\tLoss: 0.140798\n",
      "Train Epoch: 3 [16000/240000 (7%)]\tLoss: 0.226307\n",
      "Train Epoch: 3 [17000/240000 (7%)]\tLoss: 0.197694\n",
      "Train Epoch: 3 [18000/240000 (8%)]\tLoss: 0.275814\n",
      "Train Epoch: 3 [19000/240000 (8%)]\tLoss: 0.197489\n",
      "Train Epoch: 3 [20000/240000 (8%)]\tLoss: 0.244859\n",
      "Train Epoch: 3 [21000/240000 (9%)]\tLoss: 0.256991\n",
      "Train Epoch: 3 [22000/240000 (9%)]\tLoss: 0.175034\n",
      "Train Epoch: 3 [23000/240000 (10%)]\tLoss: 0.136934\n",
      "Train Epoch: 3 [24000/240000 (10%)]\tLoss: 0.218339\n",
      "Train Epoch: 3 [25000/240000 (10%)]\tLoss: 0.136376\n",
      "Train Epoch: 3 [26000/240000 (11%)]\tLoss: 0.203646\n",
      "Train Epoch: 3 [27000/240000 (11%)]\tLoss: 0.223447\n",
      "Train Epoch: 3 [28000/240000 (12%)]\tLoss: 0.196092\n",
      "Train Epoch: 3 [29000/240000 (12%)]\tLoss: 0.169684\n",
      "Train Epoch: 3 [30000/240000 (12%)]\tLoss: 0.427478\n",
      "Train Epoch: 3 [31000/240000 (13%)]\tLoss: 0.111869\n",
      "Train Epoch: 3 [32000/240000 (13%)]\tLoss: 0.192610\n",
      "Train Epoch: 3 [33000/240000 (14%)]\tLoss: 0.095397\n",
      "Train Epoch: 3 [34000/240000 (14%)]\tLoss: 0.156816\n",
      "Train Epoch: 3 [35000/240000 (15%)]\tLoss: 0.190719\n",
      "Train Epoch: 3 [36000/240000 (15%)]\tLoss: 0.160451\n",
      "Train Epoch: 3 [37000/240000 (15%)]\tLoss: 0.110384\n",
      "Train Epoch: 3 [38000/240000 (16%)]\tLoss: 0.209699\n",
      "Train Epoch: 3 [39000/240000 (16%)]\tLoss: 0.201827\n",
      "Train Epoch: 3 [40000/240000 (17%)]\tLoss: 0.223641\n",
      "Train Epoch: 3 [41000/240000 (17%)]\tLoss: 0.230473\n",
      "Train Epoch: 3 [42000/240000 (18%)]\tLoss: 0.102485\n",
      "Train Epoch: 3 [43000/240000 (18%)]\tLoss: 0.111162\n",
      "Train Epoch: 3 [44000/240000 (18%)]\tLoss: 0.160845\n",
      "Train Epoch: 3 [45000/240000 (19%)]\tLoss: 0.203141\n",
      "Train Epoch: 3 [46000/240000 (19%)]\tLoss: 0.086499\n",
      "Train Epoch: 3 [47000/240000 (20%)]\tLoss: 0.217795\n",
      "Train Epoch: 3 [48000/240000 (20%)]\tLoss: 0.229159\n",
      "Train Epoch: 3 [49000/240000 (20%)]\tLoss: 0.105175\n",
      "Train Epoch: 3 [50000/240000 (21%)]\tLoss: 0.191599\n",
      "Train Epoch: 3 [51000/240000 (21%)]\tLoss: 0.132809\n",
      "Train Epoch: 3 [52000/240000 (22%)]\tLoss: 0.343730\n",
      "Train Epoch: 3 [53000/240000 (22%)]\tLoss: 0.174992\n",
      "Train Epoch: 3 [54000/240000 (22%)]\tLoss: 0.237716\n",
      "Train Epoch: 3 [55000/240000 (23%)]\tLoss: 0.222010\n",
      "Train Epoch: 3 [56000/240000 (23%)]\tLoss: 0.215453\n",
      "Train Epoch: 3 [57000/240000 (24%)]\tLoss: 0.177226\n",
      "Train Epoch: 3 [58000/240000 (24%)]\tLoss: 0.360237\n",
      "Train Epoch: 3 [59000/240000 (25%)]\tLoss: 0.202031\n",
      "Train Epoch: 3 [60000/240000 (25%)]\tLoss: 0.114364\n",
      "Train Epoch: 3 [61000/240000 (25%)]\tLoss: 0.196162\n",
      "Train Epoch: 3 [62000/240000 (26%)]\tLoss: 0.181952\n",
      "Train Epoch: 3 [63000/240000 (26%)]\tLoss: 0.141437\n",
      "Train Epoch: 3 [64000/240000 (27%)]\tLoss: 0.208521\n",
      "Train Epoch: 3 [65000/240000 (27%)]\tLoss: 0.219693\n",
      "Train Epoch: 3 [66000/240000 (28%)]\tLoss: 0.136561\n",
      "Train Epoch: 3 [67000/240000 (28%)]\tLoss: 0.111297\n",
      "Train Epoch: 3 [68000/240000 (28%)]\tLoss: 0.154846\n",
      "Train Epoch: 3 [69000/240000 (29%)]\tLoss: 0.088012\n",
      "Train Epoch: 3 [70000/240000 (29%)]\tLoss: 0.141747\n",
      "Train Epoch: 3 [71000/240000 (30%)]\tLoss: 0.220358\n",
      "Train Epoch: 3 [72000/240000 (30%)]\tLoss: 0.111472\n",
      "Train Epoch: 3 [73000/240000 (30%)]\tLoss: 0.128737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [74000/240000 (31%)]\tLoss: 0.164567\n",
      "Train Epoch: 3 [75000/240000 (31%)]\tLoss: 0.331749\n",
      "Train Epoch: 3 [76000/240000 (32%)]\tLoss: 0.162745\n",
      "Train Epoch: 3 [77000/240000 (32%)]\tLoss: 0.244111\n",
      "Train Epoch: 3 [78000/240000 (32%)]\tLoss: 0.125904\n",
      "Train Epoch: 3 [79000/240000 (33%)]\tLoss: 0.203920\n",
      "Train Epoch: 3 [80000/240000 (33%)]\tLoss: 0.258105\n",
      "Train Epoch: 3 [81000/240000 (34%)]\tLoss: 0.181210\n",
      "Train Epoch: 3 [82000/240000 (34%)]\tLoss: 0.198082\n",
      "Train Epoch: 3 [83000/240000 (35%)]\tLoss: 0.203244\n",
      "Train Epoch: 3 [84000/240000 (35%)]\tLoss: 0.116152\n",
      "Train Epoch: 3 [85000/240000 (35%)]\tLoss: 0.273760\n",
      "Train Epoch: 3 [86000/240000 (36%)]\tLoss: 0.134069\n",
      "Train Epoch: 3 [87000/240000 (36%)]\tLoss: 0.137873\n",
      "Train Epoch: 3 [88000/240000 (37%)]\tLoss: 0.153829\n",
      "Train Epoch: 3 [89000/240000 (37%)]\tLoss: 0.094840\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-de40310e422b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                                 \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m                                 \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Time elapsed {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/CCM-ART-MNIST/models.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, train_loader, use_cuda, device, epoch, layers)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \"\"\"\n\u001b[1;32m    158\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2443\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2445\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfrombuffer\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   2389\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m  \u001b[0;31m# may change to (mode, 0, 1) post-1.1.6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2390\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_MAPMODES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2391\u001b[0;31m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2392\u001b[0m             im = im._new(\n\u001b[1;32m   2393\u001b[0m                 \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mnew\u001b[0;34m(mode, size, color)\u001b[0m\n\u001b[1;32m   2292\u001b[0m         \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageColor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2294\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Parameter Tuning\n",
    "epochs= [5,10,15]\n",
    "batch_size= [100,200,300]\n",
    "dropouts = [.2, .5, .75]\n",
    "layers=[1,2,3,4]\n",
    "filters=[10,16]\n",
    "filter_sizes=[5]\n",
    "n_units=[50,100]\n",
    "\n",
    "score=[]\n",
    "data_df = []\n",
    "data_dict={}\n",
    "key= 0 \n",
    "\n",
    "imp.reload(models)\n",
    "\n",
    "for batch in batch_size:\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.EMNIST('data/', train=True, split='digits', download=True,\n",
    "            transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "            batch_size=batch, shuffle=True, **kwargs)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.EMNIST('data/', train=False, split='digits', \n",
    "            transform=transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "            batch_size=batch, shuffle=True, **kwargs)\n",
    "\n",
    "    test_loader_ordered = torch.utils.data.DataLoader(\n",
    "        datasets.EMNIST('data/', train=False, split='digits', \n",
    "            transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "        batch_size=len(test_loader.dataset), shuffle=False, **kwargs)\n",
    "    \n",
    "    for layer in layers:\n",
    "        for drops in dropouts:\n",
    "            for f in filters:\n",
    "                for fs in filter_sizes:\n",
    "                    for units in n_units:\n",
    "                        model = models.get_model(n_layers, dropout_rate=drops, n_filters=f, filter_size=fs, fc_units=units)\n",
    "                        optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.5)\n",
    "\n",
    "                        start = datetime.now() \n",
    "                        for epoch in epochs:\n",
    "                            print('-------------------------------------------------------------\\n')\n",
    "                            print('batch_size:'batch,'layer:'layer, 'dropout_rate:'drops, 'n_filters:'f,'filter_size:',fs,'fc_units:',units,'epoch:',epoch)\n",
    "                            for e in range(epoch+1):\n",
    "                                models.train(model, optimizer, train_loader, use_cuda, device, e, layers=layer)\n",
    "                                elapsed = datetime.now() - start\n",
    "                                print('Time elapsed {}'.format(elapsed))\n",
    "                                test_loss, correct = models.test(model, optimizer, test_loader, use_cuda, device, e, layers=n_layers)\n",
    "                                scores = test_loss\n",
    "                                print(e+1,'of',epoch, batch, drops)\n",
    "\n",
    "                            #Save Iterations in Dictionary\n",
    "                            data_df.append([batch, layer, drops, f, fs, units, epoch, elapsed, test_loss, correct])\n",
    "                            data_dict[key] = {'batch_size':batch, \n",
    "                                              'layer':layer, \n",
    "                                              'dropout_rate':drops, \n",
    "                                              'n_filters':f,\n",
    "                                              'filter_size':fs,\n",
    "                                              'fc_units':units,\n",
    "                                              'epoch':epoch,\n",
    "                                              'train_time':elapsed,\n",
    "                                              'test_loss':test_loss,\n",
    "                                              'accuracy': correct}\n",
    "                            score.append(scores)\n",
    "                            key += 1  #update Dictionary key\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = list(zip(score,data_dict.values()))\n",
    "# with open('results/pytorch_results.json','w') as outfile:\n",
    "#     json.dump(data,outfile)\n",
    "    \n",
    "data_df = pd.DataFrame(data_df, columns=[*data_dict[0]])\n",
    "data_df.to_csv('results/pytorch_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>layer</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_time</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>15</td>\n",
       "      <td>00:04:03.705639</td>\n",
       "      <td>0.137968</td>\n",
       "      <td>0.959550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>00:03:02.489744</td>\n",
       "      <td>0.159959</td>\n",
       "      <td>0.953675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>00:02:00.003327</td>\n",
       "      <td>0.191470</td>\n",
       "      <td>0.944875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00:57.181999</td>\n",
       "      <td>0.257672</td>\n",
       "      <td>0.927275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_size  layer  dropout_rate  epoch      train_time  test_loss  accuracy\n",
       "3         100      1           0.2     15 00:04:03.705639   0.137968  0.959550\n",
       "2         100      1           0.2     10 00:03:02.489744   0.159959  0.953675\n",
       "1         100      1           0.2      5 00:02:00.003327   0.191470  0.944875\n",
       "0         100      1           0.2      1 00:00:57.181999   0.257672  0.927275"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[data_df.layer==1].sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>layer</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_time</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [batch_size, layer, dropout_rate, epoch, train_time, test_loss, accuracy]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[data_df.layer==2].sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>layer</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_time</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [batch_size, layer, dropout_rate, epoch, train_time, test_loss, accuracy]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[data_df.layer==3].sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>layer</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_time</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [batch_size, layer, dropout_rate, epoch, train_time, test_loss, accuracy]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[data_df.layer==4].sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
