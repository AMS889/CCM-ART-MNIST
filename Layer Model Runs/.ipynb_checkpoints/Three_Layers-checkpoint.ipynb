{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asimonoff/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import json\n",
    "import codecs\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy import io as spio\n",
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.callbacks import *\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from scipy.spatial.distance import cosine\n",
    "import tensorflow as tf\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Shaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2018) #setting a random seed so work is reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emnist = spio.loadmat(\"../data/EMNIST/emnist-digits.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the training and test sets\n",
    "x_train = emnist[\"dataset\"][0][0][0][0][0][0].astype(np.float32)\n",
    "y_train = emnist[\"dataset\"][0][0][0][0][0][1]\n",
    "\n",
    "x_test = emnist[\"dataset\"][0][0][1][0][0][0].astype(np.float32)\n",
    "y_test = emnist[\"dataset\"][0][0][1][0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing since 255 is the max value\n",
    "x_train = x_train/x_train.max()\n",
    "x_test = x_test/x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flattening pixels into vectors using order A\n",
    "x_train = x_train.reshape(x_train.shape[0], 1, 28, 28, order = 'A').astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, 28, 28, order = 'A').astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-hot encode the labels\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(layers, dropout):\n",
    "    if layers == 1:\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(20, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(dropout))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dense(50, activation='relu'))\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "        # Compile model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return model\n",
    "    if layers == 2:\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(20, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Conv2D(20, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(dropout))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dense(50, activation='relu'))\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "        # Compile model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return model\n",
    "    if layers == 3:\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(20, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Conv2D(20, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Conv2D(20, (2, 2), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(dropout))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dense(50, activation='relu'))\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "        # Compile model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return model\n",
    "    if layers == 4:\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(20, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Conv2D(20, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Conv2D(20, (2, 2), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Conv2D(20, (1, 1), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(dropout))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dense(50, activation='relu'))\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "        # Compile model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = create_model(1)\n",
    "#model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=1, batch_size=20000)\n",
    "#scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "#print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240000 samples, validate on 40000 samples\n",
      "Epoch 1/5\n",
      "240000/240000 [==============================] - 211s 879us/step - loss: 0.1669 - acc: 0.9483 - val_loss: 0.2462 - val_acc: 0.9845\n",
      "Epoch 2/5\n",
      "240000/240000 [==============================] - 206s 858us/step - loss: 0.0605 - acc: 0.9818 - val_loss: 0.2755 - val_acc: 0.9827\n",
      "Epoch 3/5\n",
      "240000/240000 [==============================] - 204s 849us/step - loss: 0.0469 - acc: 0.9861 - val_loss: 0.5743 - val_acc: 0.9636\n",
      "Epoch 4/5\n",
      "240000/240000 [==============================] - 205s 854us/step - loss: 0.0407 - acc: 0.9878 - val_loss: 0.7462 - val_acc: 0.9529\n",
      "Epoch 5/5\n",
      "240000/240000 [==============================] - 204s 851us/step - loss: 0.0365 - acc: 0.9888 - val_loss: 0.6377 - val_acc: 0.9601\n",
      "Large CNN Error: 3.99%\n",
      "5 100 0.2\n",
      "Train on 240000 samples, validate on 40000 samples\n",
      "Epoch 1/5\n",
      "240000/240000 [==============================] - 188s 784us/step - loss: 0.2394 - acc: 0.9241 - val_loss: 0.3117 - val_acc: 0.9804\n",
      "Epoch 2/5\n",
      "240000/240000 [==============================] - 188s 782us/step - loss: 0.0764 - acc: 0.9767 - val_loss: 0.2881 - val_acc: 0.9820\n",
      "Epoch 3/5\n",
      "240000/240000 [==============================] - 188s 783us/step - loss: 0.0591 - acc: 0.9824 - val_loss: 0.3617 - val_acc: 0.9773\n",
      "Epoch 4/5\n",
      "240000/240000 [==============================] - 189s 789us/step - loss: 0.0497 - acc: 0.9853 - val_loss: 0.2272 - val_acc: 0.9857\n",
      "Epoch 5/5\n",
      "240000/240000 [==============================] - 188s 784us/step - loss: 0.0442 - acc: 0.9868 - val_loss: 0.2204 - val_acc: 0.9861\n",
      "Large CNN Error: 1.39%\n",
      "5 200 0.2\n",
      "Train on 240000 samples, validate on 40000 samples\n",
      "Epoch 1/5\n",
      "240000/240000 [==============================] - 203s 844us/step - loss: 0.2759 - acc: 0.9136 - val_loss: 0.3743 - val_acc: 0.9764\n",
      "Epoch 2/5\n",
      "240000/240000 [==============================] - 200s 833us/step - loss: 0.0816 - acc: 0.9749 - val_loss: 0.2821 - val_acc: 0.9822\n",
      "Epoch 3/5\n",
      "240000/240000 [==============================] - 201s 838us/step - loss: 0.0617 - acc: 0.9814 - val_loss: 0.2687 - val_acc: 0.9831\n",
      "Epoch 4/5\n",
      "240000/240000 [==============================] - 200s 834us/step - loss: 0.0513 - acc: 0.9843 - val_loss: 0.3535 - val_acc: 0.9777\n",
      "Epoch 5/5\n",
      "240000/240000 [==============================] - 200s 833us/step - loss: 0.0455 - acc: 0.9861 - val_loss: 0.7124 - val_acc: 0.9550\n",
      "Large CNN Error: 4.50%\n",
      "5 300 0.2\n",
      "Train on 240000 samples, validate on 40000 samples\n",
      "Epoch 1/10\n",
      "240000/240000 [==============================] - 218s 908us/step - loss: 0.1805 - acc: 0.9444 - val_loss: 0.2239 - val_acc: 0.9860\n",
      "Epoch 2/10\n",
      "240000/240000 [==============================] - 214s 892us/step - loss: 0.0634 - acc: 0.9807 - val_loss: 0.2319 - val_acc: 0.9855\n",
      "Epoch 3/10\n",
      "240000/240000 [==============================] - 212s 883us/step - loss: 0.0500 - acc: 0.9847 - val_loss: 0.2149 - val_acc: 0.9865\n",
      "Epoch 4/10\n",
      "240000/240000 [==============================] - 213s 885us/step - loss: 0.0425 - acc: 0.9872 - val_loss: 0.2675 - val_acc: 0.9832\n",
      "Epoch 5/10\n",
      "240000/240000 [==============================] - 214s 891us/step - loss: 0.0385 - acc: 0.9884 - val_loss: 0.3021 - val_acc: 0.9808\n",
      "Epoch 6/10\n",
      "240000/240000 [==============================] - 214s 891us/step - loss: 0.0358 - acc: 0.9893 - val_loss: 1.0921 - val_acc: 0.9308\n",
      "Epoch 7/10\n",
      "240000/240000 [==============================] - 214s 892us/step - loss: 0.0326 - acc: 0.9903 - val_loss: 1.5843 - val_acc: 0.9007\n",
      "Epoch 8/10\n",
      "240000/240000 [==============================] - 213s 889us/step - loss: 0.0312 - acc: 0.9906 - val_loss: 0.8320 - val_acc: 0.9473\n",
      "Epoch 9/10\n",
      "240000/240000 [==============================] - 212s 885us/step - loss: 0.0298 - acc: 0.9911 - val_loss: 1.2654 - val_acc: 0.9202\n",
      "Epoch 10/10\n",
      "240000/240000 [==============================] - 214s 891us/step - loss: 0.0290 - acc: 0.9913 - val_loss: 1.6655 - val_acc: 0.8957\n",
      "Large CNN Error: 10.43%\n",
      "10 100 0.2\n",
      "Train on 240000 samples, validate on 40000 samples\n",
      "Epoch 1/10\n",
      "240000/240000 [==============================] - 200s 831us/step - loss: 0.2250 - acc: 0.9278 - val_loss: 0.2436 - val_acc: 0.9847\n",
      "Epoch 2/10\n",
      "240000/240000 [==============================] - 198s 826us/step - loss: 0.0716 - acc: 0.9783 - val_loss: 0.2682 - val_acc: 0.9831\n",
      "Epoch 3/10\n",
      "240000/240000 [==============================] - 198s 825us/step - loss: 0.0552 - acc: 0.9833 - val_loss: 0.3347 - val_acc: 0.9789\n",
      "Epoch 4/10\n",
      "240000/240000 [==============================] - 197s 819us/step - loss: 0.0465 - acc: 0.9859 - val_loss: 0.1751 - val_acc: 0.9889\n",
      "Epoch 5/10\n",
      "240000/240000 [==============================] - 198s 826us/step - loss: 0.0409 - acc: 0.9878 - val_loss: 0.4168 - val_acc: 0.9737\n",
      "Epoch 6/10\n",
      "240000/240000 [==============================] - 198s 827us/step - loss: 0.0379 - acc: 0.9884 - val_loss: 0.3141 - val_acc: 0.9801\n",
      "Epoch 7/10\n",
      "240000/240000 [==============================] - 199s 828us/step - loss: 0.0355 - acc: 0.9893 - val_loss: 0.7586 - val_acc: 0.9520\n",
      "Epoch 8/10\n",
      "240000/240000 [==============================] - 198s 825us/step - loss: 0.0321 - acc: 0.9903 - val_loss: 0.8736 - val_acc: 0.9449\n",
      "Epoch 9/10\n",
      "240000/240000 [==============================] - 197s 819us/step - loss: 0.0300 - acc: 0.9908 - val_loss: 1.2066 - val_acc: 0.9243\n",
      "Epoch 10/10\n",
      "240000/240000 [==============================] - 195s 814us/step - loss: 0.0296 - acc: 0.9910 - val_loss: 1.2530 - val_acc: 0.9216\n",
      "Large CNN Error: 7.84%\n",
      "10 200 0.2\n",
      "Train on 240000 samples, validate on 40000 samples\n",
      "Epoch 1/10\n",
      "240000/240000 [==============================] - 208s 869us/step - loss: 0.2590 - acc: 0.9178 - val_loss: 0.2576 - val_acc: 0.9838\n",
      "Epoch 2/10\n",
      "240000/240000 [==============================] - 202s 843us/step - loss: 0.0719 - acc: 0.9779 - val_loss: 0.2073 - val_acc: 0.9870\n",
      "Epoch 3/10\n",
      "240000/240000 [==============================] - 206s 860us/step - loss: 0.0583 - acc: 0.9822 - val_loss: 0.2019 - val_acc: 0.9872\n",
      "Epoch 4/10\n",
      "240000/240000 [==============================] - 204s 851us/step - loss: 0.0492 - acc: 0.9853 - val_loss: 0.2075 - val_acc: 0.9869\n",
      "Epoch 5/10\n",
      "240000/240000 [==============================] - 206s 858us/step - loss: 0.0434 - acc: 0.9869 - val_loss: 0.1700 - val_acc: 0.9892\n",
      "Epoch 6/10\n",
      "240000/240000 [==============================] - 208s 866us/step - loss: 0.0414 - acc: 0.9875 - val_loss: 0.2021 - val_acc: 0.9873\n",
      "Epoch 7/10\n",
      "240000/240000 [==============================] - 208s 866us/step - loss: 0.0372 - acc: 0.9884 - val_loss: 0.1959 - val_acc: 0.9876\n",
      "Epoch 8/10\n",
      "240000/240000 [==============================] - 204s 851us/step - loss: 0.0349 - acc: 0.9896 - val_loss: 0.2828 - val_acc: 0.9820\n",
      "Epoch 9/10\n",
      "240000/240000 [==============================] - 208s 866us/step - loss: 0.0336 - acc: 0.9898 - val_loss: 0.2351 - val_acc: 0.9852\n",
      "Epoch 10/10\n",
      "240000/240000 [==============================] - 207s 861us/step - loss: 0.0312 - acc: 0.9906 - val_loss: 0.2262 - val_acc: 0.9858\n",
      "Large CNN Error: 1.42%\n",
      "10 300 0.2\n",
      "Train on 240000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "240000/240000 [==============================] - 214s 893us/step - loss: 0.1706 - acc: 0.9474 - val_loss: 0.2576 - val_acc: 0.9838\n",
      "Epoch 2/15\n",
      "240000/240000 [==============================] - 212s 885us/step - loss: 0.0635 - acc: 0.9808 - val_loss: 0.1559 - val_acc: 0.9902\n",
      "Epoch 3/15\n",
      "240000/240000 [==============================] - 212s 885us/step - loss: 0.0493 - acc: 0.9850 - val_loss: 0.1570 - val_acc: 0.9901\n",
      "Epoch 4/15\n",
      "240000/240000 [==============================] - 213s 887us/step - loss: 0.0415 - acc: 0.9873 - val_loss: 0.1975 - val_acc: 0.9875\n",
      "Epoch 5/15\n",
      "240000/240000 [==============================] - 213s 888us/step - loss: 0.0366 - acc: 0.9889 - val_loss: 0.1661 - val_acc: 0.9896\n",
      "Epoch 6/15\n",
      "240000/240000 [==============================] - 212s 882us/step - loss: 0.0339 - acc: 0.9897 - val_loss: 0.6956 - val_acc: 0.9561\n",
      "Epoch 7/15\n",
      "240000/240000 [==============================] - 212s 884us/step - loss: 0.0317 - acc: 0.9904 - val_loss: 0.5725 - val_acc: 0.9638\n",
      "Epoch 8/15\n",
      "240000/240000 [==============================] - 212s 882us/step - loss: 0.0306 - acc: 0.9908 - val_loss: 1.0502 - val_acc: 0.9340\n",
      "Epoch 9/15\n",
      "240000/240000 [==============================] - 214s 890us/step - loss: 0.0284 - acc: 0.9913 - val_loss: 0.3899 - val_acc: 0.9754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15\n",
      "240000/240000 [==============================] - 206s 860us/step - loss: 0.0271 - acc: 0.9918 - val_loss: 1.2446 - val_acc: 0.9214\n",
      "Epoch 11/15\n",
      "240000/240000 [==============================] - 206s 858us/step - loss: 0.0264 - acc: 0.9921 - val_loss: 2.1795 - val_acc: 0.8642\n",
      "Epoch 12/15\n",
      "240000/240000 [==============================] - 207s 861us/step - loss: 0.0251 - acc: 0.9924 - val_loss: 1.7343 - val_acc: 0.8913\n",
      "Epoch 13/15\n",
      "240000/240000 [==============================] - 206s 857us/step - loss: 0.0244 - acc: 0.9926 - val_loss: 1.5252 - val_acc: 0.9045\n",
      "Epoch 14/15\n",
      "240000/240000 [==============================] - 206s 858us/step - loss: 0.0240 - acc: 0.9929 - val_loss: 1.6858 - val_acc: 0.8945\n",
      "Epoch 15/15\n",
      "240000/240000 [==============================] - 204s 850us/step - loss: 0.0233 - acc: 0.9930 - val_loss: 1.8882 - val_acc: 0.8819\n",
      "Large CNN Error: 11.81%\n",
      "15 100 0.2\n",
      "Train on 240000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "240000/240000 [==============================] - 198s 824us/step - loss: 0.2222 - acc: 0.9303 - val_loss: 0.3435 - val_acc: 0.9784\n",
      "Epoch 2/15\n",
      "240000/240000 [==============================] - 197s 819us/step - loss: 0.0693 - acc: 0.9792 - val_loss: 0.3532 - val_acc: 0.9779\n",
      "Epoch 3/15\n",
      "240000/240000 [==============================] - 196s 815us/step - loss: 0.0550 - acc: 0.9835 - val_loss: 0.3692 - val_acc: 0.9768\n",
      "Epoch 4/15\n",
      "240000/240000 [==============================] - 199s 828us/step - loss: 0.0468 - acc: 0.9856 - val_loss: 0.2632 - val_acc: 0.9835\n",
      "Epoch 5/15\n",
      "240000/240000 [==============================] - 199s 830us/step - loss: 0.0420 - acc: 0.9873 - val_loss: 0.2365 - val_acc: 0.9851\n",
      "Epoch 6/15\n",
      "240000/240000 [==============================] - 196s 818us/step - loss: 0.0383 - acc: 0.9885 - val_loss: 0.3439 - val_acc: 0.9782\n",
      "Epoch 7/15\n",
      "240000/240000 [==============================] - 194s 807us/step - loss: 0.0363 - acc: 0.9890 - val_loss: 0.5947 - val_acc: 0.9623\n",
      "Epoch 8/15\n",
      "240000/240000 [==============================] - 199s 829us/step - loss: 0.0339 - acc: 0.9898 - val_loss: 0.5594 - val_acc: 0.9647\n",
      "Epoch 9/15\n",
      "240000/240000 [==============================] - 199s 829us/step - loss: 0.0307 - acc: 0.9907 - val_loss: 0.9631 - val_acc: 0.9390\n",
      "Epoch 10/15\n",
      "240000/240000 [==============================] - 195s 812us/step - loss: 0.0301 - acc: 0.9908 - val_loss: 0.4465 - val_acc: 0.9716\n",
      "Epoch 11/15\n",
      "240000/240000 [==============================] - 198s 827us/step - loss: 0.0289 - acc: 0.9910 - val_loss: 0.8000 - val_acc: 0.9494\n",
      "Epoch 12/15\n",
      "240000/240000 [==============================] - 197s 822us/step - loss: 0.0272 - acc: 0.9919 - val_loss: 1.3090 - val_acc: 0.9177\n",
      "Epoch 13/15\n",
      "240000/240000 [==============================] - 197s 823us/step - loss: 0.0264 - acc: 0.9920 - val_loss: 1.6413 - val_acc: 0.8974\n",
      "Epoch 14/15\n",
      "240000/240000 [==============================] - 197s 821us/step - loss: 0.0262 - acc: 0.9921 - val_loss: 0.6002 - val_acc: 0.9618\n",
      "Epoch 15/15\n",
      "240000/240000 [==============================] - 196s 817us/step - loss: 0.0251 - acc: 0.9924 - val_loss: 1.3097 - val_acc: 0.9179\n",
      "Large CNN Error: 8.21%\n",
      "15 200 0.2\n",
      "Train on 240000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "240000/240000 [==============================] - 209s 869us/step - loss: 0.2592 - acc: 0.9175 - val_loss: 0.5851 - val_acc: 0.9630\n",
      "Epoch 2/15\n",
      "240000/240000 [==============================] - 206s 857us/step - loss: 0.0762 - acc: 0.9771 - val_loss: 0.2742 - val_acc: 0.9827\n",
      "Epoch 3/15\n",
      "240000/240000 [==============================] - 203s 845us/step - loss: 0.0585 - acc: 0.9822 - val_loss: 0.2129 - val_acc: 0.9867\n",
      "Epoch 4/15\n",
      "240000/240000 [==============================] - 206s 857us/step - loss: 0.0511 - acc: 0.9845 - val_loss: 0.2030 - val_acc: 0.9872\n",
      "Epoch 5/15\n",
      "240000/240000 [==============================] - 204s 850us/step - loss: 0.0455 - acc: 0.9863 - val_loss: 0.2361 - val_acc: 0.9852\n",
      "Epoch 6/15\n",
      "240000/240000 [==============================] - 204s 850us/step - loss: 0.0413 - acc: 0.9876 - val_loss: 0.2767 - val_acc: 0.9827\n",
      "Epoch 7/15\n",
      "240000/240000 [==============================] - 202s 841us/step - loss: 0.0382 - acc: 0.9886 - val_loss: 0.3523 - val_acc: 0.9778\n",
      "Epoch 8/15\n",
      "240000/240000 [==============================] - 205s 852us/step - loss: 0.0355 - acc: 0.9893 - val_loss: 0.4329 - val_acc: 0.9727\n",
      "Epoch 9/15\n",
      "240000/240000 [==============================] - 206s 857us/step - loss: 0.0335 - acc: 0.9901 - val_loss: 0.2776 - val_acc: 0.9826\n",
      "Epoch 10/15\n",
      "240000/240000 [==============================] - 206s 857us/step - loss: 0.0319 - acc: 0.9902 - val_loss: 0.3189 - val_acc: 0.9799\n",
      "Epoch 11/15\n",
      "240000/240000 [==============================] - 204s 851us/step - loss: 0.0309 - acc: 0.9906 - val_loss: 0.4790 - val_acc: 0.9699\n",
      "Epoch 12/15\n",
      "240000/240000 [==============================] - 203s 846us/step - loss: 0.0294 - acc: 0.9912 - val_loss: 0.4668 - val_acc: 0.9707\n",
      "Epoch 13/15\n",
      "240000/240000 [==============================] - 207s 864us/step - loss: 0.0283 - acc: 0.9913 - val_loss: 0.8166 - val_acc: 0.9484\n",
      "Epoch 14/15\n",
      "240000/240000 [==============================] - 205s 856us/step - loss: 0.0267 - acc: 0.9919 - val_loss: 0.6601 - val_acc: 0.9584\n",
      "Epoch 15/15\n",
      "240000/240000 [==============================] - 207s 863us/step - loss: 0.0261 - acc: 0.9921 - val_loss: 1.0814 - val_acc: 0.9319\n",
      "Large CNN Error: 6.81%\n",
      "15 300 0.2\n",
      "Train on 240000 samples, validate on 40000 samples\n",
      "Epoch 1/5\n",
      "240000/240000 [==============================] - 216s 900us/step - loss: 0.2924 - acc: 0.9071 - val_loss: 0.5338 - val_acc: 0.9663\n",
      "Epoch 2/5\n",
      "240000/240000 [==============================] - 211s 881us/step - loss: 0.1268 - acc: 0.9608 - val_loss: 0.5862 - val_acc: 0.9630\n",
      "Epoch 3/5\n",
      "240000/240000 [==============================] - 213s 888us/step - loss: 0.1008 - acc: 0.9690 - val_loss: 0.7550 - val_acc: 0.9522\n",
      "Epoch 4/5\n",
      "240000/240000 [==============================] - 214s 890us/step - loss: 0.0850 - acc: 0.9739 - val_loss: 2.2396 - val_acc: 0.8586\n",
      "Epoch 5/5\n",
      "240000/240000 [==============================] - 215s 894us/step - loss: 0.0772 - acc: 0.9760 - val_loss: 2.0594 - val_acc: 0.8692\n",
      "Large CNN Error: 13.08%\n",
      "5 100 0.5\n",
      "Train on 240000 samples, validate on 40000 samples\n",
      "Epoch 1/5\n",
      "240000/240000 [==============================] - 203s 845us/step - loss: 0.3804 - acc: 0.8779 - val_loss: 0.4655 - val_acc: 0.9706\n",
      "Epoch 2/5\n",
      "240000/240000 [==============================] - 200s 833us/step - loss: 0.1626 - acc: 0.9496 - val_loss: 0.4616 - val_acc: 0.9709\n",
      "Epoch 3/5\n",
      "240000/240000 [==============================] - 200s 834us/step - loss: 0.1294 - acc: 0.9596 - val_loss: 1.4428 - val_acc: 0.9091\n",
      "Epoch 4/5\n",
      "240000/240000 [==============================] - 202s 842us/step - loss: 0.1129 - acc: 0.9650 - val_loss: 1.6631 - val_acc: 0.8957\n",
      "Epoch 5/5\n",
      "240000/240000 [==============================] - 203s 848us/step - loss: 0.0992 - acc: 0.9691 - val_loss: 1.8061 - val_acc: 0.8866\n",
      "Large CNN Error: 11.33%\n",
      "5 200 0.5\n",
      "Train on 240000 samples, validate on 40000 samples\n",
      "Epoch 1/5\n",
      "240000/240000 [==============================] - 204s 849us/step - loss: 0.4202 - acc: 0.8650 - val_loss: 0.5873 - val_acc: 0.9631\n",
      "Epoch 2/5\n",
      "240000/240000 [==============================] - 200s 831us/step - loss: 0.1660 - acc: 0.9487 - val_loss: 0.4062 - val_acc: 0.9745\n",
      "Epoch 3/5\n",
      "240000/240000 [==============================] - 204s 851us/step - loss: 0.1304 - acc: 0.9603 - val_loss: 0.2943 - val_acc: 0.9814\n",
      "Epoch 4/5\n",
      "240000/240000 [==============================] - 202s 841us/step - loss: 0.1145 - acc: 0.9651 - val_loss: 0.3789 - val_acc: 0.9760\n",
      "Epoch 5/5\n",
      "240000/240000 [==============================] - 201s 836us/step - loss: 0.1020 - acc: 0.9690 - val_loss: 0.4899 - val_acc: 0.9690\n",
      "Large CNN Error: 3.10%\n",
      "5 300 0.5\n",
      "Train on 240000 samples, validate on 40000 samples\n",
      "Epoch 1/10\n",
      "240000/240000 [==============================] - 220s 918us/step - loss: 0.2926 - acc: 0.9072 - val_loss: 0.3398 - val_acc: 0.9786\n",
      "Epoch 2/10\n",
      "240000/240000 [==============================] - 220s 915us/step - loss: 0.1212 - acc: 0.9633 - val_loss: 0.6365 - val_acc: 0.9599\n",
      "Epoch 3/10\n",
      "240000/240000 [==============================] - 218s 909us/step - loss: 0.0943 - acc: 0.9712 - val_loss: 0.9079 - val_acc: 0.9424\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240000/240000 [==============================] - 214s 891us/step - loss: 0.0802 - acc: 0.9757 - val_loss: 1.3468 - val_acc: 0.9145\n",
      "Epoch 5/10\n",
      "240000/240000 [==============================] - 212s 884us/step - loss: 0.0722 - acc: 0.9782 - val_loss: 1.5928 - val_acc: 0.8999\n",
      "Epoch 6/10\n",
      "240000/240000 [==============================] - 215s 894us/step - loss: 0.0675 - acc: 0.9796 - val_loss: 1.8440 - val_acc: 0.8852\n",
      "Epoch 7/10\n",
      "240000/240000 [==============================] - 214s 894us/step - loss: 0.0630 - acc: 0.9811 - val_loss: 1.9556 - val_acc: 0.8782\n",
      "Epoch 8/10\n",
      "240000/240000 [==============================] - 217s 904us/step - loss: 0.0597 - acc: 0.9822 - val_loss: 2.2547 - val_acc: 0.8593\n",
      "Epoch 9/10\n",
      "240000/240000 [==============================] - 215s 896us/step - loss: 0.0570 - acc: 0.9826 - val_loss: 1.9342 - val_acc: 0.8794\n",
      "Epoch 10/10\n",
      "240000/240000 [==============================] - 215s 895us/step - loss: 0.0552 - acc: 0.9836 - val_loss: 2.1058 - val_acc: 0.8688\n",
      "Large CNN Error: 13.12%\n",
      "10 100 0.5\n",
      "Train on 240000 samples, validate on 40000 samples\n",
      "Epoch 1/10\n",
      "240000/240000 [==============================] - 203s 844us/step - loss: 0.3601 - acc: 0.8842 - val_loss: 0.3676 - val_acc: 0.9768\n",
      "Epoch 2/10\n",
      "240000/240000 [==============================] - 203s 844us/step - loss: 0.1443 - acc: 0.9562 - val_loss: 0.2853 - val_acc: 0.9820\n",
      "Epoch 3/10\n",
      "240000/240000 [==============================] - 202s 840us/step - loss: 0.1125 - acc: 0.9657 - val_loss: 0.2409 - val_acc: 0.9849\n",
      "Epoch 4/10\n",
      "240000/240000 [==============================] - 202s 840us/step - loss: 0.0964 - acc: 0.9703 - val_loss: 0.4184 - val_acc: 0.9734\n",
      "Epoch 5/10\n",
      "240000/240000 [==============================] - 202s 841us/step - loss: 0.0868 - acc: 0.9733 - val_loss: 1.0511 - val_acc: 0.9332\n",
      "Epoch 6/10\n",
      "240000/240000 [==============================] - 198s 824us/step - loss: 0.0770 - acc: 0.9765 - val_loss: 1.7789 - val_acc: 0.8892\n",
      "Epoch 7/10\n",
      "240000/240000 [==============================] - 206s 858us/step - loss: 0.0731 - acc: 0.9779 - val_loss: 1.5941 - val_acc: 0.8993\n",
      "Epoch 8/10\n",
      "240000/240000 [==============================] - 199s 830us/step - loss: 0.0691 - acc: 0.9787 - val_loss: 1.9920 - val_acc: 0.8759\n",
      "Epoch 9/10\n",
      "240000/240000 [==============================] - 201s 837us/step - loss: 0.0648 - acc: 0.9803 - val_loss: 1.9071 - val_acc: 0.8813\n",
      "Epoch 10/10\n",
      "240000/240000 [==============================] - 200s 831us/step - loss: 0.0618 - acc: 0.9813 - val_loss: 1.7977 - val_acc: 0.8880\n",
      "Large CNN Error: 11.20%\n",
      "10 200 0.5\n",
      "Train on 240000 samples, validate on 40000 samples\n",
      "Epoch 1/10\n",
      "240000/240000 [==============================] - 209s 870us/step - loss: 0.4300 - acc: 0.8621 - val_loss: 0.4604 - val_acc: 0.9711\n",
      "Epoch 2/10\n",
      "240000/240000 [==============================] - 204s 851us/step - loss: 0.1798 - acc: 0.9445 - val_loss: 0.4739 - val_acc: 0.9702\n",
      "Epoch 3/10\n",
      "240000/240000 [==============================] - 202s 841us/step - loss: 0.1410 - acc: 0.9569 - val_loss: 0.5325 - val_acc: 0.9665\n",
      "Epoch 4/10\n",
      "240000/240000 [==============================] - 202s 841us/step - loss: 0.1202 - acc: 0.9629 - val_loss: 0.5629 - val_acc: 0.9643\n",
      "Epoch 5/10\n",
      "240000/240000 [==============================] - 199s 828us/step - loss: 0.1068 - acc: 0.9673 - val_loss: 1.0304 - val_acc: 0.9347\n",
      "Epoch 6/10\n",
      "240000/240000 [==============================] - 205s 855us/step - loss: 0.0964 - acc: 0.9704 - val_loss: 1.1400 - val_acc: 0.9280\n",
      "Epoch 7/10\n",
      "240000/240000 [==============================] - 208s 868us/step - loss: 0.0889 - acc: 0.9727 - val_loss: 2.6938 - val_acc: 0.8308\n",
      "Epoch 8/10\n",
      "240000/240000 [==============================] - 203s 845us/step - loss: 0.0837 - acc: 0.9742 - val_loss: 2.5562 - val_acc: 0.8394\n",
      "Epoch 9/10\n",
      "240000/240000 [==============================] - 201s 838us/step - loss: 0.0769 - acc: 0.9762 - val_loss: 2.4509 - val_acc: 0.8466\n",
      "Epoch 10/10\n",
      "240000/240000 [==============================] - 204s 851us/step - loss: 0.0741 - acc: 0.9772 - val_loss: 2.2538 - val_acc: 0.8589\n",
      "Large CNN Error: 14.11%\n",
      "10 300 0.5\n",
      "Train on 240000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "240000/240000 [==============================] - 217s 906us/step - loss: 0.2864 - acc: 0.9092 - val_loss: 0.3943 - val_acc: 0.9752\n",
      "Epoch 2/15\n",
      "240000/240000 [==============================] - 215s 896us/step - loss: 0.1240 - acc: 0.9624 - val_loss: 0.3379 - val_acc: 0.9787\n",
      "Epoch 3/15\n",
      "240000/240000 [==============================] - 215s 896us/step - loss: 0.0986 - acc: 0.9704 - val_loss: 0.5822 - val_acc: 0.9632\n",
      "Epoch 4/15\n",
      "240000/240000 [==============================] - 213s 888us/step - loss: 0.0859 - acc: 0.9737 - val_loss: 1.0621 - val_acc: 0.9323\n",
      "Epoch 5/15\n",
      "240000/240000 [==============================] - 214s 892us/step - loss: 0.0750 - acc: 0.9771 - val_loss: 2.5762 - val_acc: 0.8392\n",
      "Epoch 6/15\n",
      "240000/240000 [==============================] - 210s 873us/step - loss: 0.0695 - acc: 0.9786 - val_loss: 2.1395 - val_acc: 0.8664\n",
      "Epoch 7/15\n",
      "240000/240000 [==============================] - 208s 868us/step - loss: 0.0653 - acc: 0.9801 - val_loss: 2.3849 - val_acc: 0.8513\n",
      "Epoch 8/15\n",
      "240000/240000 [==============================] - 209s 871us/step - loss: 0.0618 - acc: 0.9813 - val_loss: 2.3663 - val_acc: 0.8521\n",
      "Epoch 9/15\n",
      "240000/240000 [==============================] - 208s 866us/step - loss: 0.0585 - acc: 0.9824 - val_loss: 2.2675 - val_acc: 0.8584\n",
      "Epoch 10/15\n",
      "240000/240000 [==============================] - 210s 876us/step - loss: 0.0573 - acc: 0.9826 - val_loss: 1.9448 - val_acc: 0.8788\n",
      "Epoch 11/15\n",
      "240000/240000 [==============================] - 209s 870us/step - loss: 0.0556 - acc: 0.9830 - val_loss: 1.9557 - val_acc: 0.8782\n",
      "Epoch 12/15\n",
      "240000/240000 [==============================] - 209s 873us/step - loss: 0.0536 - acc: 0.9838 - val_loss: 2.0160 - val_acc: 0.8741\n",
      "Epoch 13/15\n",
      "240000/240000 [==============================] - 208s 866us/step - loss: 0.0513 - acc: 0.9844 - val_loss: 1.8547 - val_acc: 0.8840\n",
      "Epoch 14/15\n",
      "240000/240000 [==============================] - 209s 871us/step - loss: 0.0503 - acc: 0.9847 - val_loss: 1.8470 - val_acc: 0.8846\n",
      "Epoch 15/15\n",
      "240000/240000 [==============================] - 207s 861us/step - loss: 0.0496 - acc: 0.9849 - val_loss: 1.9720 - val_acc: 0.8767\n",
      "Large CNN Error: 12.33%\n",
      "15 100 0.5\n",
      "Train on 240000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "240000/240000 [==============================] - 205s 852us/step - loss: 0.3479 - acc: 0.8873 - val_loss: 0.5780 - val_acc: 0.9636\n",
      "Epoch 2/15\n",
      "240000/240000 [==============================] - 205s 853us/step - loss: 0.1392 - acc: 0.9570 - val_loss: 0.5965 - val_acc: 0.9625\n",
      "Epoch 3/15\n",
      "240000/240000 [==============================] - 202s 844us/step - loss: 0.1116 - acc: 0.9662 - val_loss: 0.7715 - val_acc: 0.9513\n",
      "Epoch 4/15\n",
      "240000/240000 [==============================] - 201s 838us/step - loss: 0.0956 - acc: 0.9707 - val_loss: 1.8661 - val_acc: 0.8827\n",
      "Epoch 5/15\n",
      "240000/240000 [==============================] - 201s 837us/step - loss: 0.0842 - acc: 0.9741 - val_loss: 2.0069 - val_acc: 0.8750\n",
      "Epoch 6/15\n",
      "240000/240000 [==============================] - 202s 840us/step - loss: 0.0769 - acc: 0.9763 - val_loss: 2.1416 - val_acc: 0.8664\n",
      "Epoch 7/15\n",
      "240000/240000 [==============================] - 203s 844us/step - loss: 0.0713 - acc: 0.9783 - val_loss: 1.9483 - val_acc: 0.8788\n",
      "Epoch 8/15\n",
      "240000/240000 [==============================] - 204s 850us/step - loss: 0.0682 - acc: 0.9792 - val_loss: 2.0327 - val_acc: 0.8733\n",
      "Epoch 9/15\n",
      "240000/240000 [==============================] - 208s 867us/step - loss: 0.0646 - acc: 0.9801 - val_loss: 2.4529 - val_acc: 0.8469\n",
      "Epoch 10/15\n",
      "240000/240000 [==============================] - 205s 856us/step - loss: 0.0612 - acc: 0.9812 - val_loss: 1.9546 - val_acc: 0.8783\n",
      "Epoch 11/15\n",
      "240000/240000 [==============================] - 204s 851us/step - loss: 0.0596 - acc: 0.9819 - val_loss: 2.0962 - val_acc: 0.8693\n",
      "Epoch 12/15\n",
      "240000/240000 [==============================] - 201s 836us/step - loss: 0.0574 - acc: 0.9828 - val_loss: 2.0575 - val_acc: 0.8717\n",
      "Epoch 13/15\n",
      "240000/240000 [==============================] - 205s 855us/step - loss: 0.0573 - acc: 0.9828 - val_loss: 2.2656 - val_acc: 0.8584\n",
      "Epoch 14/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240000/240000 [==============================] - 206s 859us/step - loss: 0.0542 - acc: 0.9835 - val_loss: 2.0657 - val_acc: 0.8711\n",
      "Epoch 15/15\n",
      "240000/240000 [==============================] - 202s 842us/step - loss: 0.0537 - acc: 0.9835 - val_loss: 2.0322 - val_acc: 0.8733\n",
      "Large CNN Error: 12.67%\n",
      "15 200 0.5\n",
      "Train on 240000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "240000/240000 [==============================] - 208s 867us/step - loss: 0.3917 - acc: 0.8735 - val_loss: 0.6053 - val_acc: 0.9619\n",
      "Epoch 2/15\n",
      "240000/240000 [==============================] - 207s 861us/step - loss: 0.1546 - acc: 0.9526 - val_loss: 1.5892 - val_acc: 0.8995\n",
      "Epoch 3/15\n",
      "240000/240000 [==============================] - 205s 854us/step - loss: 0.1218 - acc: 0.9631 - val_loss: 2.4012 - val_acc: 0.8497\n",
      "Epoch 4/15\n",
      "240000/240000 [==============================] - 204s 849us/step - loss: 0.1064 - acc: 0.9675 - val_loss: 2.8435 - val_acc: 0.8226\n",
      "Epoch 5/15\n",
      "240000/240000 [==============================] - 203s 846us/step - loss: 0.0938 - acc: 0.9717 - val_loss: 2.2086 - val_acc: 0.8624\n",
      "Epoch 6/15\n",
      "240000/240000 [==============================] - 202s 841us/step - loss: 0.0861 - acc: 0.9742 - val_loss: 2.1697 - val_acc: 0.8650\n",
      "Epoch 7/15\n",
      "240000/240000 [==============================] - 203s 845us/step - loss: 0.0767 - acc: 0.9768 - val_loss: 1.9273 - val_acc: 0.8801\n",
      "Epoch 8/15\n",
      "240000/240000 [==============================] - 207s 861us/step - loss: 0.0731 - acc: 0.9778 - val_loss: 2.0145 - val_acc: 0.8743\n",
      "Epoch 9/15\n",
      "240000/240000 [==============================] - 202s 840us/step - loss: 0.0680 - acc: 0.9794 - val_loss: 2.0702 - val_acc: 0.8708\n",
      "Epoch 10/15\n",
      "240000/240000 [==============================] - 204s 849us/step - loss: 0.0662 - acc: 0.9796 - val_loss: 2.2094 - val_acc: 0.8622\n",
      "Epoch 11/15\n",
      "240000/240000 [==============================] - 210s 873us/step - loss: 0.0620 - acc: 0.9808 - val_loss: 2.1499 - val_acc: 0.8660\n",
      "Epoch 12/15\n",
      "240000/240000 [==============================] - 207s 864us/step - loss: 0.0600 - acc: 0.9819 - val_loss: 1.9203 - val_acc: 0.8803\n",
      "Epoch 13/15\n",
      "240000/240000 [==============================] - 206s 859us/step - loss: 0.0580 - acc: 0.9821 - val_loss: 1.9787 - val_acc: 0.8768\n",
      "Epoch 14/15\n",
      "240000/240000 [==============================] - 207s 862us/step - loss: 0.0560 - acc: 0.9829 - val_loss: 1.9286 - val_acc: 0.8798\n",
      "Epoch 15/15\n",
      "240000/240000 [==============================] - 205s 856us/step - loss: 0.0544 - acc: 0.9834 - val_loss: 2.0597 - val_acc: 0.8716\n",
      "Large CNN Error: 12.84%\n",
      "15 300 0.5\n",
      "Train on 240000 samples, validate on 40000 samples\n",
      "Epoch 1/5\n",
      "240000/240000 [==============================] - 234s 976us/step - loss: 0.5922 - acc: 0.7992 - val_loss: 2.9965 - val_acc: 0.8122\n",
      "Epoch 2/5\n",
      "240000/240000 [==============================] - 384s 2ms/step - loss: 0.3211 - acc: 0.8952 - val_loss: 4.2196 - val_acc: 0.7367\n",
      "Epoch 3/5\n",
      "240000/240000 [==============================] - 668s 3ms/step - loss: 0.2630 - acc: 0.9151 - val_loss: 4.6040 - val_acc: 0.7125\n",
      "Epoch 4/5\n",
      "240000/240000 [==============================] - 723s 3ms/step - loss: 0.2269 - acc: 0.9274 - val_loss: 4.3230 - val_acc: 0.7304\n",
      "Epoch 5/5\n",
      "240000/240000 [==============================] - 247s 1ms/step - loss: 0.2052 - acc: 0.9350 - val_loss: 4.0695 - val_acc: 0.7460\n",
      "Large CNN Error: 25.39%\n",
      "5 100 0.75\n",
      "Train on 240000 samples, validate on 40000 samples\n",
      "Epoch 1/5\n",
      "240000/240000 [==============================] - 245s 1ms/step - loss: 0.6751 - acc: 0.7736 - val_loss: 0.9448 - val_acc: 0.9403\n",
      "Epoch 2/5\n",
      "240000/240000 [==============================] - 234s 976us/step - loss: 0.3607 - acc: 0.8831 - val_loss: 1.2516 - val_acc: 0.9207\n",
      "Epoch 3/5\n",
      "240000/240000 [==============================] - 225s 936us/step - loss: 0.2948 - acc: 0.9055 - val_loss: 1.5149 - val_acc: 0.9042\n",
      "Epoch 4/5\n",
      "240000/240000 [==============================] - 241s 1ms/step - loss: 0.2551 - acc: 0.9186 - val_loss: 2.3030 - val_acc: 0.8561\n",
      "Epoch 5/5\n",
      "240000/240000 [==============================] - 237s 988us/step - loss: 0.2306 - acc: 0.9261 - val_loss: 2.0690 - val_acc: 0.8707\n",
      "Large CNN Error: 12.93%\n",
      "5 200 0.75\n",
      "Train on 240000 samples, validate on 40000 samples\n",
      "Epoch 1/5\n",
      "240000/240000 [==============================] - 226s 940us/step - loss: 0.7251 - acc: 0.7575 - val_loss: 1.6325 - val_acc: 0.8963\n",
      "Epoch 2/5\n",
      "240000/240000 [==============================] - 211s 880us/step - loss: 0.3686 - acc: 0.8814 - val_loss: 2.2509 - val_acc: 0.8592\n",
      "Epoch 3/5\n",
      "240000/240000 [==============================] - 206s 860us/step - loss: 0.2974 - acc: 0.9055 - val_loss: 2.1663 - val_acc: 0.8649\n",
      "Epoch 4/5\n",
      "240000/240000 [==============================] - 214s 893us/step - loss: 0.2588 - acc: 0.9190 - val_loss: 2.3356 - val_acc: 0.8540\n",
      "Epoch 5/5\n",
      "240000/240000 [==============================] - 220s 918us/step - loss: 0.2306 - acc: 0.9279 - val_loss: 2.3916 - val_acc: 0.8504\n",
      "Large CNN Error: 14.96%\n",
      "5 300 0.75\n",
      "Train on 240000 samples, validate on 40000 samples\n",
      "Epoch 1/10\n",
      "240000/240000 [==============================] - 223s 928us/step - loss: 0.5635 - acc: 0.8136 - val_loss: 3.1100 - val_acc: 0.8044\n",
      "Epoch 2/10\n",
      "240000/240000 [==============================] - 228s 949us/step - loss: 0.3129 - acc: 0.9016 - val_loss: 2.9513 - val_acc: 0.8147\n",
      "Epoch 3/10\n",
      "240000/240000 [==============================] - 234s 976us/step - loss: 0.2545 - acc: 0.9205 - val_loss: 4.3339 - val_acc: 0.7277\n",
      "Epoch 4/10\n",
      "240000/240000 [==============================] - 230s 957us/step - loss: 0.2209 - acc: 0.9318 - val_loss: 4.8544 - val_acc: 0.6953\n",
      "Epoch 5/10\n",
      "240000/240000 [==============================] - 228s 949us/step - loss: 0.1986 - acc: 0.9387 - val_loss: 5.4029 - val_acc: 0.6607\n",
      "Epoch 6/10\n",
      "240000/240000 [==============================] - 225s 939us/step - loss: 0.1858 - acc: 0.9427 - val_loss: 5.2745 - val_acc: 0.6687\n",
      "Epoch 7/10\n",
      "240000/240000 [==============================] - 226s 941us/step - loss: 0.1722 - acc: 0.9475 - val_loss: 6.1597 - val_acc: 0.6127\n",
      "Epoch 8/10\n",
      "240000/240000 [==============================] - 225s 938us/step - loss: 0.1653 - acc: 0.9488 - val_loss: 4.9268 - val_acc: 0.6899\n",
      "Epoch 9/10\n",
      "240000/240000 [==============================] - 232s 968us/step - loss: 0.1559 - acc: 0.9523 - val_loss: 6.8486 - val_acc: 0.5689\n",
      "Epoch 10/10\n",
      "240000/240000 [==============================] - 235s 981us/step - loss: 0.1531 - acc: 0.9529 - val_loss: 5.5419 - val_acc: 0.6507\n",
      "Large CNN Error: 34.93%\n",
      "10 100 0.75\n",
      "Train on 240000 samples, validate on 40000 samples\n",
      "Epoch 1/10\n",
      "240000/240000 [==============================] - 220s 919us/step - loss: 0.7109 - acc: 0.7569 - val_loss: 0.9789 - val_acc: 0.9381\n",
      "Epoch 2/10\n",
      "240000/240000 [==============================] - 217s 903us/step - loss: 0.3885 - acc: 0.8715 - val_loss: 1.5595 - val_acc: 0.9014\n",
      "Epoch 3/10\n",
      "240000/240000 [==============================] - 219s 912us/step - loss: 0.3190 - acc: 0.8951 - val_loss: 2.6921 - val_acc: 0.8316\n",
      "Epoch 4/10\n",
      "240000/240000 [==============================] - 213s 888us/step - loss: 0.2771 - acc: 0.9097 - val_loss: 2.6945 - val_acc: 0.8312\n",
      "Epoch 5/10\n",
      "240000/240000 [==============================] - 218s 908us/step - loss: 0.2510 - acc: 0.9178 - val_loss: 2.4349 - val_acc: 0.8476\n",
      "Epoch 6/10\n",
      "240000/240000 [==============================] - 220s 918us/step - loss: 0.2330 - acc: 0.9246 - val_loss: 3.6528 - val_acc: 0.7714\n",
      "Epoch 7/10\n",
      "240000/240000 [==============================] - 214s 892us/step - loss: 0.2160 - acc: 0.9306 - val_loss: 4.8312 - val_acc: 0.6979\n",
      "Epoch 8/10\n",
      "240000/240000 [==============================] - 219s 914us/step - loss: 0.2046 - acc: 0.9343 - val_loss: 3.1296 - val_acc: 0.8036\n",
      "Epoch 9/10\n",
      "240000/240000 [==============================] - 215s 896us/step - loss: 0.1939 - acc: 0.9384 - val_loss: 2.8801 - val_acc: 0.8189\n",
      "Epoch 10/10\n",
      "240000/240000 [==============================] - 218s 910us/step - loss: 0.1878 - acc: 0.9404 - val_loss: 3.4969 - val_acc: 0.7785\n",
      "Large CNN Error: 22.16%\n",
      "10 200 0.75\n",
      "Train on 240000 samples, validate on 40000 samples\n",
      "Epoch 1/10\n",
      "240000/240000 [==============================] - 217s 903us/step - loss: 0.7574 - acc: 0.7434 - val_loss: 0.9099 - val_acc: 0.9424\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240000/240000 [==============================] - 215s 894us/step - loss: 0.4334 - acc: 0.8581 - val_loss: 1.3771 - val_acc: 0.9131\n",
      "Epoch 3/10\n",
      "240000/240000 [==============================] - 212s 884us/step - loss: 0.3659 - acc: 0.8808 - val_loss: 2.6744 - val_acc: 0.8314\n",
      "Epoch 4/10\n",
      "240000/240000 [==============================] - 214s 890us/step - loss: 0.3209 - acc: 0.8955 - val_loss: 2.8041 - val_acc: 0.8238\n",
      "Epoch 5/10\n",
      "240000/240000 [==============================] - 214s 891us/step - loss: 0.2832 - acc: 0.9092 - val_loss: 3.5961 - val_acc: 0.7744\n",
      "Epoch 6/10\n",
      "240000/240000 [==============================] - 214s 891us/step - loss: 0.2554 - acc: 0.9183 - val_loss: 4.2580 - val_acc: 0.7335\n",
      "Epoch 7/10\n",
      "240000/240000 [==============================] - 210s 876us/step - loss: 0.2357 - acc: 0.9250 - val_loss: 4.7135 - val_acc: 0.7053\n",
      "Epoch 8/10\n",
      "240000/240000 [==============================] - 225s 936us/step - loss: 0.2178 - acc: 0.9307 - val_loss: 4.7769 - val_acc: 0.7014\n",
      "Epoch 9/10\n",
      "240000/240000 [==============================] - 222s 925us/step - loss: 0.2046 - acc: 0.9355 - val_loss: 5.2152 - val_acc: 0.6735\n",
      "Epoch 10/10\n",
      "240000/240000 [==============================] - 214s 892us/step - loss: 0.1952 - acc: 0.9384 - val_loss: 4.9079 - val_acc: 0.6920\n",
      "Large CNN Error: 30.79%\n",
      "10 300 0.75\n",
      "Train on 240000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "240000/240000 [==============================] - 236s 983us/step - loss: 0.6083 - acc: 0.7959 - val_loss: 0.6440 - val_acc: 0.9592\n",
      "Epoch 2/15\n",
      "240000/240000 [==============================] - 231s 963us/step - loss: 0.3352 - acc: 0.8913 - val_loss: 1.4078 - val_acc: 0.9101\n",
      "Epoch 3/15\n",
      "240000/240000 [==============================] - 233s 972us/step - loss: 0.2708 - acc: 0.9134 - val_loss: 2.7434 - val_acc: 0.8279\n",
      "Epoch 4/15\n",
      "240000/240000 [==============================] - 229s 955us/step - loss: 0.2364 - acc: 0.9242 - val_loss: 2.3538 - val_acc: 0.8514\n",
      "Epoch 5/15\n",
      "240000/240000 [==============================] - 217s 902us/step - loss: 0.2133 - acc: 0.9325 - val_loss: 2.5312 - val_acc: 0.8406\n",
      "Epoch 6/15\n",
      "240000/240000 [==============================] - 216s 899us/step - loss: 0.1959 - acc: 0.9377 - val_loss: 2.9728 - val_acc: 0.8126\n",
      "Epoch 7/15\n",
      "240000/240000 [==============================] - 219s 914us/step - loss: 0.1878 - acc: 0.9407 - val_loss: 3.3686 - val_acc: 0.7875\n",
      "Epoch 8/15\n",
      "240000/240000 [==============================] - 271s 1ms/step - loss: 0.1760 - acc: 0.9445 - val_loss: 3.5237 - val_acc: 0.7780\n",
      "Epoch 9/15\n",
      "240000/240000 [==============================] - 252s 1ms/step - loss: 0.1691 - acc: 0.9472 - val_loss: 3.6838 - val_acc: 0.7680\n",
      "Epoch 10/15\n",
      "240000/240000 [==============================] - 244s 1ms/step - loss: 0.1608 - acc: 0.9492 - val_loss: 4.3172 - val_acc: 0.7271\n",
      "Epoch 11/15\n",
      "240000/240000 [==============================] - 258s 1ms/step - loss: 0.1570 - acc: 0.9510 - val_loss: 5.1124 - val_acc: 0.6789\n",
      "Epoch 12/15\n",
      "240000/240000 [==============================] - 260s 1ms/step - loss: 0.1501 - acc: 0.9532 - val_loss: 5.3486 - val_acc: 0.6637\n",
      "Epoch 13/15\n",
      "240000/240000 [==============================] - 246s 1ms/step - loss: 0.1485 - acc: 0.9538 - val_loss: 5.7946 - val_acc: 0.6356\n",
      "Epoch 14/15\n",
      "240000/240000 [==============================] - 241s 1ms/step - loss: 0.1438 - acc: 0.9550 - val_loss: 5.2967 - val_acc: 0.6653\n",
      "Epoch 15/15\n",
      "240000/240000 [==============================] - 241s 1ms/step - loss: 0.1383 - acc: 0.9571 - val_loss: 6.1133 - val_acc: 0.6169\n",
      "Large CNN Error: 38.31%\n",
      "15 100 0.75\n",
      "Train on 240000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "240000/240000 [==============================] - 248s 1ms/step - loss: 0.6665 - acc: 0.7772 - val_loss: 2.6037 - val_acc: 0.8362\n",
      "Epoch 2/15\n",
      "240000/240000 [==============================] - 244s 1ms/step - loss: 0.3451 - acc: 0.8902 - val_loss: 3.2375 - val_acc: 0.7967\n",
      "Epoch 3/15\n",
      "240000/240000 [==============================] - 237s 989us/step - loss: 0.2667 - acc: 0.9168 - val_loss: 3.3059 - val_acc: 0.7926\n",
      "Epoch 4/15\n",
      "240000/240000 [==============================] - 251s 1ms/step - loss: 0.2288 - acc: 0.9291 - val_loss: 4.7275 - val_acc: 0.7048\n",
      "Epoch 5/15\n",
      "240000/240000 [==============================] - 233s 970us/step - loss: 0.2077 - acc: 0.9361 - val_loss: 4.2291 - val_acc: 0.7342\n",
      "Epoch 6/15\n",
      "240000/240000 [==============================] - 221s 921us/step - loss: 0.1909 - acc: 0.9407 - val_loss: 4.5109 - val_acc: 0.7171\n",
      "Epoch 7/15\n",
      "240000/240000 [==============================] - 213s 889us/step - loss: 0.1796 - acc: 0.9442 - val_loss: 4.8872 - val_acc: 0.6948\n",
      "Epoch 8/15\n",
      "240000/240000 [==============================] - 222s 925us/step - loss: 0.1715 - acc: 0.9469 - val_loss: 5.2962 - val_acc: 0.6686\n",
      "Epoch 9/15\n",
      "240000/240000 [==============================] - 218s 908us/step - loss: 0.1646 - acc: 0.9498 - val_loss: 6.0739 - val_acc: 0.6206\n",
      "Epoch 10/15\n",
      "240000/240000 [==============================] - 212s 882us/step - loss: 0.1574 - acc: 0.9512 - val_loss: 5.4088 - val_acc: 0.6609\n",
      "Epoch 11/15\n",
      "240000/240000 [==============================] - 209s 873us/step - loss: 0.1522 - acc: 0.9533 - val_loss: 5.7247 - val_acc: 0.6422\n",
      "Epoch 12/15\n",
      "240000/240000 [==============================] - 205s 856us/step - loss: 0.1504 - acc: 0.9536 - val_loss: 5.3896 - val_acc: 0.6623\n",
      "Epoch 13/15\n",
      "240000/240000 [==============================] - 209s 873us/step - loss: 0.1474 - acc: 0.9551 - val_loss: 6.4112 - val_acc: 0.5990\n",
      "Epoch 14/15\n",
      "240000/240000 [==============================] - 224s 933us/step - loss: 0.1430 - acc: 0.9562 - val_loss: 5.6202 - val_acc: 0.6478\n",
      "Epoch 15/15\n",
      "240000/240000 [==============================] - 244s 1ms/step - loss: 0.1397 - acc: 0.9565 - val_loss: 6.3224 - val_acc: 0.6051\n",
      "Large CNN Error: 39.49%\n",
      "15 200 0.75\n",
      "Train on 240000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "240000/240000 [==============================] - 219s 915us/step - loss: 0.6815 - acc: 0.7724 - val_loss: 2.6404 - val_acc: 0.8352\n",
      "Epoch 2/15\n",
      "240000/240000 [==============================] - 219s 914us/step - loss: 0.3617 - acc: 0.8843 - val_loss: 3.1515 - val_acc: 0.8029\n",
      "Epoch 3/15\n",
      "240000/240000 [==============================] - 222s 926us/step - loss: 0.2996 - acc: 0.9050 - val_loss: 4.1235 - val_acc: 0.7417\n",
      "Epoch 4/15\n",
      "240000/240000 [==============================] - 220s 917us/step - loss: 0.2641 - acc: 0.9166 - val_loss: 5.3390 - val_acc: 0.6666\n",
      "Epoch 5/15\n",
      "240000/240000 [==============================] - 224s 934us/step - loss: 0.2357 - acc: 0.9260 - val_loss: 4.2982 - val_acc: 0.7319\n",
      "Epoch 6/15\n",
      "240000/240000 [==============================] - 212s 884us/step - loss: 0.2182 - acc: 0.9319 - val_loss: 5.2594 - val_acc: 0.6719\n",
      "Epoch 7/15\n",
      "240000/240000 [==============================] - 212s 884us/step - loss: 0.2041 - acc: 0.9362 - val_loss: 6.5136 - val_acc: 0.5933\n",
      "Epoch 8/15\n",
      "240000/240000 [==============================] - 206s 857us/step - loss: 0.1930 - acc: 0.9397 - val_loss: 6.0125 - val_acc: 0.6248\n",
      "Epoch 9/15\n",
      "240000/240000 [==============================] - 214s 893us/step - loss: 0.1846 - acc: 0.9417 - val_loss: 5.4270 - val_acc: 0.6609\n",
      "Epoch 10/15\n",
      "240000/240000 [==============================] - 224s 932us/step - loss: 0.1774 - acc: 0.9448 - val_loss: 5.3573 - val_acc: 0.6651\n",
      "Epoch 11/15\n",
      "240000/240000 [==============================] - 235s 977us/step - loss: 0.1689 - acc: 0.9476 - val_loss: 5.6919 - val_acc: 0.6441\n",
      "Epoch 12/15\n",
      "240000/240000 [==============================] - 220s 919us/step - loss: 0.1641 - acc: 0.9492 - val_loss: 4.8735 - val_acc: 0.6946\n",
      "Epoch 13/15\n",
      "240000/240000 [==============================] - 214s 892us/step - loss: 0.1588 - acc: 0.9510 - val_loss: 5.9788 - val_acc: 0.6259\n",
      "Epoch 14/15\n",
      "240000/240000 [==============================] - 219s 914us/step - loss: 0.1564 - acc: 0.9513 - val_loss: 5.5239 - val_acc: 0.6543\n",
      "Epoch 15/15\n",
      "240000/240000 [==============================] - 227s 944us/step - loss: 0.1515 - acc: 0.9531 - val_loss: 5.7381 - val_acc: 0.6406\n",
      "Large CNN Error: 35.94%\n",
      "15 300 0.75\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2e2d5470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Parameter Tuning\n",
    "epochs= [5,10,15]\n",
    "batch_size= [100,200,300]\n",
    "dropouts = [.2, .5, .75]\n",
    "#layers=[1,2,3,4]\n",
    "history=History()\n",
    "\n",
    "score=[]\n",
    "data_dict={}\n",
    "key= 0 \n",
    "layer=3\n",
    "#for layer in layers:\n",
    "for drops in dropouts:\n",
    "    for epoch in epochs:\n",
    "        for batch in batch_size:\n",
    "            model = create_model(layer, drops)\n",
    "            model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=epoch, batch_size=batch, callbacks=[history])\n",
    "            scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "            print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))\n",
    "            print(epoch, batch, drops)\n",
    "\n",
    "            #Save Iterations in Dictionary\n",
    "            data_dict[key]={'layer':layer, 'epoch':epoch, 'batch_size':batch, 'dropout_rate':drops}\n",
    "            score.append(scores[1])\n",
    "            key += 1  #update Dictionary key\n",
    "\n",
    "            # summarize history for accuracy\n",
    "            plt.plot(history.history['acc'])\n",
    "            plt.plot(history.history['val_acc'])\n",
    "            plt.title('model accuracy')\n",
    "            plt.ylabel('accuracy')\n",
    "            plt.xlabel('epoch')\n",
    "            plt.legend(['train', 'test'], loc='upper left')\n",
    "            plt.savefig('../results/plots/acc'+ '%s-%s-%s-%s' % (layer, epoch, batch, int(drops*100))+'.png')\n",
    "            plt.clf()\n",
    "\n",
    "\n",
    "            # summarize history for loss\n",
    "            plt.plot(history.history['loss'])\n",
    "            plt.plot(history.history['val_loss'])\n",
    "            plt.title('model loss')\n",
    "            plt.ylabel('loss')\n",
    "            plt.xlabel('epoch')\n",
    "            plt.legend(['train', 'test'], loc='upper left')\n",
    "            plt.savefig('../results/plots/loss'+ '%s-%s-%s-%s' % (layer, epoch, batch, int(drops*100))+'.png')\n",
    "            plt.clf()\n",
    "\n",
    "            data=np.concatenate([history.history['val_loss'],history.history['val_acc'],history.history['loss'],history.history['acc']])\n",
    "            np.savez_compressed('../results/data/'+ '%s-%s-%s-%s' % (layer, epoch, batch, drops), data)\n",
    "\n",
    "data= list(zip(score,data_dict.values()))\n",
    "with open('../results/data.json','w') as outfile:\n",
    "    json.dump(data,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
