{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import helper\n",
    "import models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import importlib as imp\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms, utils\n",
    "\n",
    "rs = 2018\n",
    "random.seed(rs)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the tensor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda: False\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print('Using cuda: {}'.format(use_cuda))\n",
    "torch.manual_seed(rs)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "batch_size = 1000\n",
    "n_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.EMNIST('data/', train=True, split='digits', download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.EMNIST('data/', train=False, split='digits', transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader_ordered = torch.utils.data.DataLoader(\n",
    "    datasets.EMNIST('data/', train=False, split='digits', transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=len(test_loader.dataset), shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing across all parameters\n",
    "\n",
    "**Note:** Netx represents an x layer network between 1 and 4 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [0/240000 (0%)]\tLoss: 2.326792\n",
      "Train Epoch: 5 [1000/240000 (0%)]\tLoss: 2.298206\n",
      "Train Epoch: 5 [2000/240000 (1%)]\tLoss: 2.275814\n",
      "Train Epoch: 5 [3000/240000 (1%)]\tLoss: 2.263617\n",
      "Train Epoch: 5 [4000/240000 (2%)]\tLoss: 2.246646\n",
      "Train Epoch: 5 [5000/240000 (2%)]\tLoss: 2.230634\n",
      "Train Epoch: 5 [6000/240000 (2%)]\tLoss: 2.258646\n",
      "Train Epoch: 5 [7000/240000 (3%)]\tLoss: 2.185967\n",
      "Train Epoch: 5 [8000/240000 (3%)]\tLoss: 2.154522\n",
      "Train Epoch: 5 [9000/240000 (4%)]\tLoss: 2.115901\n",
      "Train Epoch: 5 [10000/240000 (4%)]\tLoss: 2.098731\n",
      "Train Epoch: 5 [11000/240000 (5%)]\tLoss: 2.106208\n",
      "Train Epoch: 5 [12000/240000 (5%)]\tLoss: 2.059592\n",
      "Train Epoch: 5 [13000/240000 (5%)]\tLoss: 2.056937\n",
      "Train Epoch: 5 [14000/240000 (6%)]\tLoss: 2.051334\n",
      "Train Epoch: 5 [15000/240000 (6%)]\tLoss: 1.980890\n",
      "Train Epoch: 5 [16000/240000 (7%)]\tLoss: 1.936581\n",
      "Train Epoch: 5 [17000/240000 (7%)]\tLoss: 1.912089\n",
      "Train Epoch: 5 [18000/240000 (8%)]\tLoss: 1.878988\n",
      "Train Epoch: 5 [19000/240000 (8%)]\tLoss: 1.796971\n",
      "Train Epoch: 5 [20000/240000 (8%)]\tLoss: 1.846847\n",
      "Train Epoch: 5 [21000/240000 (9%)]\tLoss: 1.740394\n",
      "Train Epoch: 5 [22000/240000 (9%)]\tLoss: 1.693208\n",
      "Train Epoch: 5 [23000/240000 (10%)]\tLoss: 1.704215\n",
      "Train Epoch: 5 [24000/240000 (10%)]\tLoss: 1.649225\n",
      "Train Epoch: 5 [25000/240000 (10%)]\tLoss: 1.641113\n",
      "Train Epoch: 5 [26000/240000 (11%)]\tLoss: 1.502141\n",
      "Train Epoch: 5 [27000/240000 (11%)]\tLoss: 1.443051\n",
      "Train Epoch: 5 [28000/240000 (12%)]\tLoss: 1.477110\n",
      "Train Epoch: 5 [29000/240000 (12%)]\tLoss: 1.413789\n",
      "Train Epoch: 5 [30000/240000 (12%)]\tLoss: 1.432130\n",
      "Train Epoch: 5 [31000/240000 (13%)]\tLoss: 1.403984\n",
      "Train Epoch: 5 [32000/240000 (13%)]\tLoss: 1.226521\n",
      "Train Epoch: 5 [33000/240000 (14%)]\tLoss: 1.252247\n",
      "Train Epoch: 5 [34000/240000 (14%)]\tLoss: 1.184635\n",
      "Train Epoch: 5 [35000/240000 (15%)]\tLoss: 1.328323\n",
      "Train Epoch: 5 [36000/240000 (15%)]\tLoss: 1.226736\n",
      "Train Epoch: 5 [37000/240000 (15%)]\tLoss: 1.178144\n",
      "Train Epoch: 5 [38000/240000 (16%)]\tLoss: 1.090209\n",
      "Train Epoch: 5 [39000/240000 (16%)]\tLoss: 1.052618\n",
      "Train Epoch: 5 [40000/240000 (17%)]\tLoss: 1.110371\n",
      "Train Epoch: 5 [41000/240000 (17%)]\tLoss: 1.128826\n",
      "Train Epoch: 5 [42000/240000 (18%)]\tLoss: 0.993376\n",
      "Train Epoch: 5 [43000/240000 (18%)]\tLoss: 0.926489\n",
      "Train Epoch: 5 [44000/240000 (18%)]\tLoss: 0.842861\n",
      "Train Epoch: 5 [45000/240000 (19%)]\tLoss: 0.939938\n",
      "Train Epoch: 5 [46000/240000 (19%)]\tLoss: 0.823818\n",
      "Train Epoch: 5 [47000/240000 (20%)]\tLoss: 0.835068\n",
      "Train Epoch: 5 [48000/240000 (20%)]\tLoss: 0.885991\n",
      "Train Epoch: 5 [49000/240000 (20%)]\tLoss: 0.799851\n",
      "Train Epoch: 5 [50000/240000 (21%)]\tLoss: 0.936480\n",
      "Train Epoch: 5 [51000/240000 (21%)]\tLoss: 0.799265\n",
      "Train Epoch: 5 [52000/240000 (22%)]\tLoss: 0.753307\n",
      "Train Epoch: 5 [53000/240000 (22%)]\tLoss: 0.773808\n",
      "Train Epoch: 5 [54000/240000 (22%)]\tLoss: 0.711079\n",
      "Train Epoch: 5 [55000/240000 (23%)]\tLoss: 0.689820\n",
      "Train Epoch: 5 [56000/240000 (23%)]\tLoss: 0.647796\n",
      "Train Epoch: 5 [57000/240000 (24%)]\tLoss: 0.746622\n",
      "Train Epoch: 5 [58000/240000 (24%)]\tLoss: 0.658306\n",
      "Train Epoch: 5 [59000/240000 (25%)]\tLoss: 0.778275\n",
      "Train Epoch: 5 [60000/240000 (25%)]\tLoss: 0.794979\n",
      "Train Epoch: 5 [61000/240000 (25%)]\tLoss: 0.610128\n",
      "Train Epoch: 5 [62000/240000 (26%)]\tLoss: 0.742506\n",
      "Train Epoch: 5 [63000/240000 (26%)]\tLoss: 0.721797\n",
      "Train Epoch: 5 [64000/240000 (27%)]\tLoss: 0.594697\n",
      "Train Epoch: 5 [65000/240000 (27%)]\tLoss: 0.687651\n",
      "Train Epoch: 5 [66000/240000 (28%)]\tLoss: 0.683931\n",
      "Train Epoch: 5 [67000/240000 (28%)]\tLoss: 0.571388\n",
      "Train Epoch: 5 [68000/240000 (28%)]\tLoss: 0.660377\n",
      "Train Epoch: 5 [69000/240000 (29%)]\tLoss: 0.744674\n",
      "Train Epoch: 5 [70000/240000 (29%)]\tLoss: 0.575668\n",
      "Train Epoch: 5 [71000/240000 (30%)]\tLoss: 0.663542\n",
      "Train Epoch: 5 [72000/240000 (30%)]\tLoss: 0.567029\n",
      "Train Epoch: 5 [73000/240000 (30%)]\tLoss: 0.519696\n",
      "Train Epoch: 5 [74000/240000 (31%)]\tLoss: 0.496612\n",
      "Train Epoch: 5 [75000/240000 (31%)]\tLoss: 0.662602\n",
      "Train Epoch: 5 [76000/240000 (32%)]\tLoss: 0.493973\n",
      "Train Epoch: 5 [77000/240000 (32%)]\tLoss: 0.423848\n",
      "Train Epoch: 5 [78000/240000 (32%)]\tLoss: 0.598384\n",
      "Train Epoch: 5 [79000/240000 (33%)]\tLoss: 0.605001\n",
      "Train Epoch: 5 [80000/240000 (33%)]\tLoss: 0.623686\n",
      "Train Epoch: 5 [81000/240000 (34%)]\tLoss: 0.652719\n",
      "Train Epoch: 5 [82000/240000 (34%)]\tLoss: 0.508693\n",
      "Train Epoch: 5 [83000/240000 (35%)]\tLoss: 0.632150\n",
      "Train Epoch: 5 [84000/240000 (35%)]\tLoss: 0.550204\n",
      "Train Epoch: 5 [85000/240000 (35%)]\tLoss: 0.472786\n",
      "Train Epoch: 5 [86000/240000 (36%)]\tLoss: 0.366473\n",
      "Train Epoch: 5 [87000/240000 (36%)]\tLoss: 0.665092\n",
      "Train Epoch: 5 [88000/240000 (37%)]\tLoss: 0.588381\n",
      "Train Epoch: 5 [89000/240000 (37%)]\tLoss: 0.640450\n",
      "Train Epoch: 5 [90000/240000 (38%)]\tLoss: 0.677256\n",
      "Train Epoch: 5 [91000/240000 (38%)]\tLoss: 0.517206\n",
      "Train Epoch: 5 [92000/240000 (38%)]\tLoss: 0.374794\n",
      "Train Epoch: 5 [93000/240000 (39%)]\tLoss: 0.443714\n",
      "Train Epoch: 5 [94000/240000 (39%)]\tLoss: 0.509407\n",
      "Train Epoch: 5 [95000/240000 (40%)]\tLoss: 0.492232\n",
      "Train Epoch: 5 [96000/240000 (40%)]\tLoss: 0.529455\n",
      "Train Epoch: 5 [97000/240000 (40%)]\tLoss: 0.538122\n",
      "Train Epoch: 5 [98000/240000 (41%)]\tLoss: 0.478348\n",
      "Train Epoch: 5 [99000/240000 (41%)]\tLoss: 0.393305\n",
      "Train Epoch: 5 [100000/240000 (42%)]\tLoss: 0.389272\n",
      "Train Epoch: 5 [101000/240000 (42%)]\tLoss: 0.519147\n",
      "Train Epoch: 5 [102000/240000 (42%)]\tLoss: 0.418161\n",
      "Train Epoch: 5 [103000/240000 (43%)]\tLoss: 0.546822\n",
      "Train Epoch: 5 [104000/240000 (43%)]\tLoss: 0.613588\n",
      "Train Epoch: 5 [105000/240000 (44%)]\tLoss: 0.577663\n",
      "Train Epoch: 5 [106000/240000 (44%)]\tLoss: 0.340602\n",
      "Train Epoch: 5 [107000/240000 (45%)]\tLoss: 0.426213\n",
      "Train Epoch: 5 [108000/240000 (45%)]\tLoss: 0.617698\n",
      "Train Epoch: 5 [109000/240000 (45%)]\tLoss: 0.499628\n",
      "Train Epoch: 5 [110000/240000 (46%)]\tLoss: 0.405296\n",
      "Train Epoch: 5 [111000/240000 (46%)]\tLoss: 0.444113\n",
      "Train Epoch: 5 [112000/240000 (47%)]\tLoss: 0.420114\n",
      "Train Epoch: 5 [113000/240000 (47%)]\tLoss: 0.465770\n",
      "Train Epoch: 5 [114000/240000 (48%)]\tLoss: 0.488929\n",
      "Train Epoch: 5 [115000/240000 (48%)]\tLoss: 0.334560\n",
      "Train Epoch: 5 [116000/240000 (48%)]\tLoss: 0.422300\n",
      "Train Epoch: 5 [117000/240000 (49%)]\tLoss: 0.428449\n",
      "Train Epoch: 5 [118000/240000 (49%)]\tLoss: 0.364593\n",
      "Train Epoch: 5 [119000/240000 (50%)]\tLoss: 0.564034\n",
      "Train Epoch: 5 [120000/240000 (50%)]\tLoss: 0.357165\n",
      "Train Epoch: 5 [121000/240000 (50%)]\tLoss: 0.384433\n",
      "Train Epoch: 5 [122000/240000 (51%)]\tLoss: 0.535964\n",
      "Train Epoch: 5 [123000/240000 (51%)]\tLoss: 0.290688\n",
      "Train Epoch: 5 [124000/240000 (52%)]\tLoss: 0.330352\n",
      "Train Epoch: 5 [125000/240000 (52%)]\tLoss: 0.456892\n",
      "Train Epoch: 5 [126000/240000 (52%)]\tLoss: 0.409351\n",
      "Train Epoch: 5 [127000/240000 (53%)]\tLoss: 0.481571\n",
      "Train Epoch: 5 [128000/240000 (53%)]\tLoss: 0.412609\n",
      "Train Epoch: 5 [129000/240000 (54%)]\tLoss: 0.412053\n",
      "Train Epoch: 5 [130000/240000 (54%)]\tLoss: 0.304949\n",
      "Train Epoch: 5 [131000/240000 (55%)]\tLoss: 0.437438\n",
      "Train Epoch: 5 [132000/240000 (55%)]\tLoss: 0.341562\n",
      "Train Epoch: 5 [133000/240000 (55%)]\tLoss: 0.402969\n",
      "Train Epoch: 5 [134000/240000 (56%)]\tLoss: 0.391537\n",
      "Train Epoch: 5 [135000/240000 (56%)]\tLoss: 0.387199\n",
      "Train Epoch: 5 [136000/240000 (57%)]\tLoss: 0.502917\n",
      "Train Epoch: 5 [137000/240000 (57%)]\tLoss: 0.565870\n",
      "Train Epoch: 5 [138000/240000 (58%)]\tLoss: 0.394677\n",
      "Train Epoch: 5 [139000/240000 (58%)]\tLoss: 0.459643\n",
      "Train Epoch: 5 [140000/240000 (58%)]\tLoss: 0.358145\n",
      "Train Epoch: 5 [141000/240000 (59%)]\tLoss: 0.375836\n",
      "Train Epoch: 5 [142000/240000 (59%)]\tLoss: 0.509626\n",
      "Train Epoch: 5 [143000/240000 (60%)]\tLoss: 0.359023\n",
      "Train Epoch: 5 [144000/240000 (60%)]\tLoss: 0.444930\n",
      "Train Epoch: 5 [145000/240000 (60%)]\tLoss: 0.370681\n",
      "Train Epoch: 5 [146000/240000 (61%)]\tLoss: 0.457018\n",
      "Train Epoch: 5 [147000/240000 (61%)]\tLoss: 0.376424\n",
      "Train Epoch: 5 [148000/240000 (62%)]\tLoss: 0.417812\n",
      "Train Epoch: 5 [149000/240000 (62%)]\tLoss: 0.440168\n",
      "Train Epoch: 5 [150000/240000 (62%)]\tLoss: 0.405696\n",
      "Train Epoch: 5 [151000/240000 (63%)]\tLoss: 0.342343\n",
      "Train Epoch: 5 [152000/240000 (63%)]\tLoss: 0.305171\n",
      "Train Epoch: 5 [153000/240000 (64%)]\tLoss: 0.504087\n",
      "Train Epoch: 5 [154000/240000 (64%)]\tLoss: 0.384439\n",
      "Train Epoch: 5 [155000/240000 (65%)]\tLoss: 0.476246\n",
      "Train Epoch: 5 [156000/240000 (65%)]\tLoss: 0.354640\n",
      "Train Epoch: 5 [157000/240000 (65%)]\tLoss: 0.427939\n",
      "Train Epoch: 5 [158000/240000 (66%)]\tLoss: 0.361167\n",
      "Train Epoch: 5 [159000/240000 (66%)]\tLoss: 0.439910\n",
      "Train Epoch: 5 [160000/240000 (67%)]\tLoss: 0.401424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [161000/240000 (67%)]\tLoss: 0.239279\n",
      "Train Epoch: 5 [162000/240000 (68%)]\tLoss: 0.389505\n",
      "Train Epoch: 5 [163000/240000 (68%)]\tLoss: 0.399636\n",
      "Train Epoch: 5 [164000/240000 (68%)]\tLoss: 0.524110\n",
      "Train Epoch: 5 [165000/240000 (69%)]\tLoss: 0.382741\n",
      "Train Epoch: 5 [166000/240000 (69%)]\tLoss: 0.209045\n",
      "Train Epoch: 5 [167000/240000 (70%)]\tLoss: 0.466427\n",
      "Train Epoch: 5 [168000/240000 (70%)]\tLoss: 0.349516\n",
      "Train Epoch: 5 [169000/240000 (70%)]\tLoss: 0.363623\n",
      "Train Epoch: 5 [170000/240000 (71%)]\tLoss: 0.363059\n",
      "Train Epoch: 5 [171000/240000 (71%)]\tLoss: 0.296950\n",
      "Train Epoch: 5 [172000/240000 (72%)]\tLoss: 0.507606\n",
      "Train Epoch: 5 [173000/240000 (72%)]\tLoss: 0.331676\n",
      "Train Epoch: 5 [174000/240000 (72%)]\tLoss: 0.352191\n",
      "Train Epoch: 5 [175000/240000 (73%)]\tLoss: 0.370896\n",
      "Train Epoch: 5 [176000/240000 (73%)]\tLoss: 0.430103\n",
      "Train Epoch: 5 [177000/240000 (74%)]\tLoss: 0.428244\n",
      "Train Epoch: 5 [178000/240000 (74%)]\tLoss: 0.295272\n",
      "Train Epoch: 5 [179000/240000 (75%)]\tLoss: 0.308679\n",
      "Train Epoch: 5 [180000/240000 (75%)]\tLoss: 0.288520\n",
      "Train Epoch: 5 [181000/240000 (75%)]\tLoss: 0.504257\n",
      "Train Epoch: 5 [182000/240000 (76%)]\tLoss: 0.329613\n",
      "Train Epoch: 5 [183000/240000 (76%)]\tLoss: 0.323808\n",
      "Train Epoch: 5 [184000/240000 (77%)]\tLoss: 0.309755\n",
      "Train Epoch: 5 [185000/240000 (77%)]\tLoss: 0.414404\n",
      "Train Epoch: 5 [186000/240000 (78%)]\tLoss: 0.341402\n",
      "Train Epoch: 5 [187000/240000 (78%)]\tLoss: 0.154768\n",
      "Train Epoch: 5 [188000/240000 (78%)]\tLoss: 0.448948\n",
      "Train Epoch: 5 [189000/240000 (79%)]\tLoss: 0.408625\n",
      "Train Epoch: 5 [190000/240000 (79%)]\tLoss: 0.408844\n",
      "Train Epoch: 5 [191000/240000 (80%)]\tLoss: 0.398175\n",
      "Train Epoch: 5 [192000/240000 (80%)]\tLoss: 0.282125\n",
      "Train Epoch: 5 [193000/240000 (80%)]\tLoss: 0.304706\n",
      "Train Epoch: 5 [194000/240000 (81%)]\tLoss: 0.255315\n",
      "Train Epoch: 5 [195000/240000 (81%)]\tLoss: 0.400630\n",
      "Train Epoch: 5 [196000/240000 (82%)]\tLoss: 0.257906\n",
      "Train Epoch: 5 [197000/240000 (82%)]\tLoss: 0.240546\n",
      "Train Epoch: 5 [198000/240000 (82%)]\tLoss: 0.447352\n",
      "Train Epoch: 5 [199000/240000 (83%)]\tLoss: 0.386849\n",
      "Train Epoch: 5 [200000/240000 (83%)]\tLoss: 0.291965\n",
      "Train Epoch: 5 [201000/240000 (84%)]\tLoss: 0.351835\n",
      "Train Epoch: 5 [202000/240000 (84%)]\tLoss: 0.414005\n",
      "Train Epoch: 5 [203000/240000 (85%)]\tLoss: 0.344783\n",
      "Train Epoch: 5 [204000/240000 (85%)]\tLoss: 0.412035\n",
      "Train Epoch: 5 [205000/240000 (85%)]\tLoss: 0.419363\n",
      "Train Epoch: 5 [206000/240000 (86%)]\tLoss: 0.346218\n",
      "Train Epoch: 5 [207000/240000 (86%)]\tLoss: 0.256163\n",
      "Train Epoch: 5 [208000/240000 (87%)]\tLoss: 0.192036\n",
      "Train Epoch: 5 [209000/240000 (87%)]\tLoss: 0.246906\n",
      "Train Epoch: 5 [210000/240000 (88%)]\tLoss: 0.427045\n",
      "Train Epoch: 5 [211000/240000 (88%)]\tLoss: 0.296379\n",
      "Train Epoch: 5 [212000/240000 (88%)]\tLoss: 0.316822\n",
      "Train Epoch: 5 [213000/240000 (89%)]\tLoss: 0.257614\n",
      "Train Epoch: 5 [214000/240000 (89%)]\tLoss: 0.270387\n",
      "Train Epoch: 5 [215000/240000 (90%)]\tLoss: 0.538455\n",
      "Train Epoch: 5 [216000/240000 (90%)]\tLoss: 0.459592\n",
      "Train Epoch: 5 [217000/240000 (90%)]\tLoss: 0.289937\n",
      "Train Epoch: 5 [218000/240000 (91%)]\tLoss: 0.283337\n",
      "Train Epoch: 5 [219000/240000 (91%)]\tLoss: 0.491261\n",
      "Train Epoch: 5 [220000/240000 (92%)]\tLoss: 0.300779\n",
      "Train Epoch: 5 [221000/240000 (92%)]\tLoss: 0.271932\n",
      "Train Epoch: 5 [222000/240000 (92%)]\tLoss: 0.265633\n",
      "Train Epoch: 5 [223000/240000 (93%)]\tLoss: 0.271551\n",
      "Train Epoch: 5 [224000/240000 (93%)]\tLoss: 0.343531\n",
      "Train Epoch: 5 [225000/240000 (94%)]\tLoss: 0.202743\n",
      "Train Epoch: 5 [226000/240000 (94%)]\tLoss: 0.490616\n",
      "Train Epoch: 5 [227000/240000 (95%)]\tLoss: 0.344058\n",
      "Train Epoch: 5 [228000/240000 (95%)]\tLoss: 0.199367\n",
      "Train Epoch: 5 [229000/240000 (95%)]\tLoss: 0.401243\n",
      "Train Epoch: 5 [230000/240000 (96%)]\tLoss: 0.486589\n",
      "Train Epoch: 5 [231000/240000 (96%)]\tLoss: 0.337278\n",
      "Train Epoch: 5 [232000/240000 (97%)]\tLoss: 0.216183\n",
      "Train Epoch: 5 [233000/240000 (97%)]\tLoss: 0.282255\n",
      "Train Epoch: 5 [234000/240000 (98%)]\tLoss: 0.253511\n",
      "Train Epoch: 5 [235000/240000 (98%)]\tLoss: 0.306922\n",
      "Train Epoch: 5 [236000/240000 (98%)]\tLoss: 0.208074\n",
      "Train Epoch: 5 [237000/240000 (99%)]\tLoss: 0.286453\n",
      "Train Epoch: 5 [238000/240000 (99%)]\tLoss: 0.239802\n",
      "Train Epoch: 5 [239000/240000 (100%)]\tLoss: 0.277572\n",
      "Time elapsed 0:00:53.386580\n",
      "\n",
      "Test set: Average loss: 0.2521, Accuracy: 37126.0/40000 (93%)\n",
      "\n",
      "5 100 0.2\n",
      "Train Epoch: 5 [0/240000 (0%)]\tLoss: 2.306161\n",
      "Train Epoch: 5 [1000/240000 (0%)]\tLoss: 2.299145\n",
      "Train Epoch: 5 [2000/240000 (1%)]\tLoss: 2.300147\n",
      "Train Epoch: 5 [3000/240000 (1%)]\tLoss: 2.261378\n",
      "Train Epoch: 5 [4000/240000 (2%)]\tLoss: 2.227987\n",
      "Train Epoch: 5 [5000/240000 (2%)]\tLoss: 2.243165\n",
      "Train Epoch: 5 [6000/240000 (2%)]\tLoss: 2.247947\n",
      "Train Epoch: 5 [7000/240000 (3%)]\tLoss: 2.209597\n",
      "Train Epoch: 5 [8000/240000 (3%)]\tLoss: 2.198349\n",
      "Train Epoch: 5 [9000/240000 (4%)]\tLoss: 2.157844\n",
      "Train Epoch: 5 [10000/240000 (4%)]\tLoss: 2.189767\n",
      "Train Epoch: 5 [11000/240000 (5%)]\tLoss: 2.169331\n",
      "Train Epoch: 5 [12000/240000 (5%)]\tLoss: 2.100785\n",
      "Train Epoch: 5 [13000/240000 (5%)]\tLoss: 2.105759\n",
      "Train Epoch: 5 [14000/240000 (6%)]\tLoss: 2.117726\n",
      "Train Epoch: 5 [15000/240000 (6%)]\tLoss: 2.071745\n",
      "Train Epoch: 5 [16000/240000 (7%)]\tLoss: 2.060123\n",
      "Train Epoch: 5 [17000/240000 (7%)]\tLoss: 2.074058\n",
      "Train Epoch: 5 [18000/240000 (8%)]\tLoss: 2.022102\n",
      "Train Epoch: 5 [19000/240000 (8%)]\tLoss: 1.998687\n",
      "Train Epoch: 5 [20000/240000 (8%)]\tLoss: 2.019967\n",
      "Train Epoch: 5 [21000/240000 (9%)]\tLoss: 1.980703\n",
      "Train Epoch: 5 [22000/240000 (9%)]\tLoss: 1.869433\n",
      "Train Epoch: 5 [23000/240000 (10%)]\tLoss: 1.930820\n",
      "Train Epoch: 5 [24000/240000 (10%)]\tLoss: 1.885565\n",
      "Train Epoch: 5 [25000/240000 (10%)]\tLoss: 1.834031\n",
      "Train Epoch: 5 [26000/240000 (11%)]\tLoss: 1.793999\n",
      "Train Epoch: 5 [27000/240000 (11%)]\tLoss: 1.801521\n",
      "Train Epoch: 5 [28000/240000 (12%)]\tLoss: 1.723292\n",
      "Train Epoch: 5 [29000/240000 (12%)]\tLoss: 1.713820\n",
      "Train Epoch: 5 [30000/240000 (12%)]\tLoss: 1.731607\n",
      "Train Epoch: 5 [31000/240000 (13%)]\tLoss: 1.719521\n",
      "Train Epoch: 5 [32000/240000 (13%)]\tLoss: 1.617424\n",
      "Train Epoch: 5 [33000/240000 (14%)]\tLoss: 1.713403\n",
      "Train Epoch: 5 [34000/240000 (14%)]\tLoss: 1.539362\n",
      "Train Epoch: 5 [35000/240000 (15%)]\tLoss: 1.552819\n",
      "Train Epoch: 5 [36000/240000 (15%)]\tLoss: 1.644233\n",
      "Train Epoch: 5 [37000/240000 (15%)]\tLoss: 1.526817\n",
      "Train Epoch: 5 [38000/240000 (16%)]\tLoss: 1.474194\n",
      "Train Epoch: 5 [39000/240000 (16%)]\tLoss: 1.408372\n",
      "Train Epoch: 5 [40000/240000 (17%)]\tLoss: 1.450150\n",
      "Train Epoch: 5 [41000/240000 (17%)]\tLoss: 1.455155\n",
      "Train Epoch: 5 [42000/240000 (18%)]\tLoss: 1.312372\n",
      "Train Epoch: 5 [43000/240000 (18%)]\tLoss: 1.354639\n",
      "Train Epoch: 5 [44000/240000 (18%)]\tLoss: 1.265926\n",
      "Train Epoch: 5 [45000/240000 (19%)]\tLoss: 1.291283\n",
      "Train Epoch: 5 [46000/240000 (19%)]\tLoss: 1.254189\n",
      "Train Epoch: 5 [47000/240000 (20%)]\tLoss: 1.299428\n",
      "Train Epoch: 5 [48000/240000 (20%)]\tLoss: 1.269871\n",
      "Train Epoch: 5 [49000/240000 (20%)]\tLoss: 1.201276\n",
      "Train Epoch: 5 [50000/240000 (21%)]\tLoss: 1.205104\n",
      "Train Epoch: 5 [51000/240000 (21%)]\tLoss: 1.211568\n",
      "Train Epoch: 5 [52000/240000 (22%)]\tLoss: 1.038523\n",
      "Train Epoch: 5 [53000/240000 (22%)]\tLoss: 1.187467\n",
      "Train Epoch: 5 [54000/240000 (22%)]\tLoss: 1.130529\n",
      "Train Epoch: 5 [55000/240000 (23%)]\tLoss: 1.139471\n",
      "Train Epoch: 5 [56000/240000 (23%)]\tLoss: 1.145780\n",
      "Train Epoch: 5 [57000/240000 (24%)]\tLoss: 1.119215\n",
      "Train Epoch: 5 [58000/240000 (24%)]\tLoss: 1.028716\n",
      "Train Epoch: 5 [59000/240000 (25%)]\tLoss: 1.018632\n",
      "Train Epoch: 5 [60000/240000 (25%)]\tLoss: 0.959901\n",
      "Train Epoch: 5 [61000/240000 (25%)]\tLoss: 0.972941\n",
      "Train Epoch: 5 [62000/240000 (26%)]\tLoss: 1.028493\n",
      "Train Epoch: 5 [63000/240000 (26%)]\tLoss: 0.997279\n",
      "Train Epoch: 5 [64000/240000 (27%)]\tLoss: 1.012018\n",
      "Train Epoch: 5 [65000/240000 (27%)]\tLoss: 0.894599\n",
      "Train Epoch: 5 [66000/240000 (28%)]\tLoss: 0.996283\n",
      "Train Epoch: 5 [67000/240000 (28%)]\tLoss: 0.914514\n",
      "Train Epoch: 5 [68000/240000 (28%)]\tLoss: 0.848252\n",
      "Train Epoch: 5 [69000/240000 (29%)]\tLoss: 0.842392\n",
      "Train Epoch: 5 [70000/240000 (29%)]\tLoss: 0.824702\n",
      "Train Epoch: 5 [71000/240000 (30%)]\tLoss: 1.049590\n",
      "Train Epoch: 5 [72000/240000 (30%)]\tLoss: 0.700247\n",
      "Train Epoch: 5 [73000/240000 (30%)]\tLoss: 0.779492\n",
      "Train Epoch: 5 [74000/240000 (31%)]\tLoss: 0.835804\n",
      "Train Epoch: 5 [75000/240000 (31%)]\tLoss: 0.781129\n",
      "Train Epoch: 5 [76000/240000 (32%)]\tLoss: 0.844550\n",
      "Train Epoch: 5 [77000/240000 (32%)]\tLoss: 0.859295\n",
      "Train Epoch: 5 [78000/240000 (32%)]\tLoss: 1.030622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [79000/240000 (33%)]\tLoss: 0.762474\n",
      "Train Epoch: 5 [80000/240000 (33%)]\tLoss: 0.796042\n",
      "Train Epoch: 5 [81000/240000 (34%)]\tLoss: 0.897549\n",
      "Train Epoch: 5 [82000/240000 (34%)]\tLoss: 0.806355\n",
      "Train Epoch: 5 [83000/240000 (35%)]\tLoss: 0.751665\n",
      "Train Epoch: 5 [84000/240000 (35%)]\tLoss: 0.791398\n",
      "Train Epoch: 5 [85000/240000 (35%)]\tLoss: 0.805529\n",
      "Train Epoch: 5 [86000/240000 (36%)]\tLoss: 0.670129\n",
      "Train Epoch: 5 [87000/240000 (36%)]\tLoss: 0.679174\n",
      "Train Epoch: 5 [88000/240000 (37%)]\tLoss: 0.821832\n",
      "Train Epoch: 5 [89000/240000 (37%)]\tLoss: 0.795781\n",
      "Train Epoch: 5 [90000/240000 (38%)]\tLoss: 0.633927\n",
      "Train Epoch: 5 [91000/240000 (38%)]\tLoss: 0.849702\n",
      "Train Epoch: 5 [92000/240000 (38%)]\tLoss: 0.714790\n",
      "Train Epoch: 5 [93000/240000 (39%)]\tLoss: 0.733404\n",
      "Train Epoch: 5 [94000/240000 (39%)]\tLoss: 0.766937\n",
      "Train Epoch: 5 [95000/240000 (40%)]\tLoss: 0.697761\n",
      "Train Epoch: 5 [96000/240000 (40%)]\tLoss: 0.699044\n",
      "Train Epoch: 5 [97000/240000 (40%)]\tLoss: 0.680159\n",
      "Train Epoch: 5 [98000/240000 (41%)]\tLoss: 0.753395\n",
      "Train Epoch: 5 [99000/240000 (41%)]\tLoss: 0.750095\n",
      "Train Epoch: 5 [100000/240000 (42%)]\tLoss: 0.598142\n",
      "Train Epoch: 5 [101000/240000 (42%)]\tLoss: 0.662938\n",
      "Train Epoch: 5 [102000/240000 (42%)]\tLoss: 0.572907\n",
      "Train Epoch: 5 [103000/240000 (43%)]\tLoss: 0.566352\n",
      "Train Epoch: 5 [104000/240000 (43%)]\tLoss: 0.805225\n",
      "Train Epoch: 5 [105000/240000 (44%)]\tLoss: 0.641905\n",
      "Train Epoch: 5 [106000/240000 (44%)]\tLoss: 0.720689\n",
      "Train Epoch: 5 [107000/240000 (45%)]\tLoss: 0.692106\n",
      "Train Epoch: 5 [108000/240000 (45%)]\tLoss: 0.791020\n",
      "Train Epoch: 5 [109000/240000 (45%)]\tLoss: 0.603232\n",
      "Train Epoch: 5 [110000/240000 (46%)]\tLoss: 0.655178\n",
      "Train Epoch: 5 [111000/240000 (46%)]\tLoss: 0.656450\n",
      "Train Epoch: 5 [112000/240000 (47%)]\tLoss: 0.646578\n",
      "Train Epoch: 5 [113000/240000 (47%)]\tLoss: 0.807970\n",
      "Train Epoch: 5 [114000/240000 (48%)]\tLoss: 0.727454\n",
      "Train Epoch: 5 [115000/240000 (48%)]\tLoss: 0.703250\n",
      "Train Epoch: 5 [116000/240000 (48%)]\tLoss: 0.652555\n",
      "Train Epoch: 5 [117000/240000 (49%)]\tLoss: 0.707800\n",
      "Train Epoch: 5 [118000/240000 (49%)]\tLoss: 0.755195\n",
      "Train Epoch: 5 [119000/240000 (50%)]\tLoss: 0.552210\n",
      "Train Epoch: 5 [120000/240000 (50%)]\tLoss: 0.701199\n",
      "Train Epoch: 5 [121000/240000 (50%)]\tLoss: 0.404377\n",
      "Train Epoch: 5 [122000/240000 (51%)]\tLoss: 0.676268\n",
      "Train Epoch: 5 [123000/240000 (51%)]\tLoss: 0.673292\n",
      "Train Epoch: 5 [124000/240000 (52%)]\tLoss: 0.633919\n",
      "Train Epoch: 5 [125000/240000 (52%)]\tLoss: 0.712910\n",
      "Train Epoch: 5 [126000/240000 (52%)]\tLoss: 0.626267\n",
      "Train Epoch: 5 [127000/240000 (53%)]\tLoss: 0.542756\n",
      "Train Epoch: 5 [128000/240000 (53%)]\tLoss: 0.664223\n",
      "Train Epoch: 5 [129000/240000 (54%)]\tLoss: 0.677293\n",
      "Train Epoch: 5 [130000/240000 (54%)]\tLoss: 0.732375\n",
      "Train Epoch: 5 [131000/240000 (55%)]\tLoss: 0.686073\n",
      "Train Epoch: 5 [132000/240000 (55%)]\tLoss: 0.666505\n",
      "Train Epoch: 5 [133000/240000 (55%)]\tLoss: 0.748687\n",
      "Train Epoch: 5 [134000/240000 (56%)]\tLoss: 0.656872\n",
      "Train Epoch: 5 [135000/240000 (56%)]\tLoss: 0.634842\n",
      "Train Epoch: 5 [136000/240000 (57%)]\tLoss: 0.424421\n",
      "Train Epoch: 5 [137000/240000 (57%)]\tLoss: 0.550878\n",
      "Train Epoch: 5 [138000/240000 (58%)]\tLoss: 0.598916\n",
      "Train Epoch: 5 [139000/240000 (58%)]\tLoss: 0.611430\n",
      "Train Epoch: 5 [140000/240000 (58%)]\tLoss: 0.566286\n",
      "Train Epoch: 5 [141000/240000 (59%)]\tLoss: 0.670046\n",
      "Train Epoch: 5 [142000/240000 (59%)]\tLoss: 0.611578\n",
      "Train Epoch: 5 [143000/240000 (60%)]\tLoss: 0.663745\n",
      "Train Epoch: 5 [144000/240000 (60%)]\tLoss: 0.599587\n",
      "Train Epoch: 5 [145000/240000 (60%)]\tLoss: 0.778831\n",
      "Train Epoch: 5 [146000/240000 (61%)]\tLoss: 0.539933\n",
      "Train Epoch: 5 [147000/240000 (61%)]\tLoss: 0.727269\n",
      "Train Epoch: 5 [148000/240000 (62%)]\tLoss: 0.675641\n",
      "Train Epoch: 5 [149000/240000 (62%)]\tLoss: 0.544124\n",
      "Train Epoch: 5 [150000/240000 (62%)]\tLoss: 0.445274\n",
      "Train Epoch: 5 [151000/240000 (63%)]\tLoss: 0.620483\n",
      "Train Epoch: 5 [152000/240000 (63%)]\tLoss: 0.531566\n",
      "Train Epoch: 5 [153000/240000 (64%)]\tLoss: 0.600126\n",
      "Train Epoch: 5 [154000/240000 (64%)]\tLoss: 0.491038\n",
      "Train Epoch: 5 [155000/240000 (65%)]\tLoss: 0.409662\n",
      "Train Epoch: 5 [156000/240000 (65%)]\tLoss: 0.546950\n",
      "Train Epoch: 5 [157000/240000 (65%)]\tLoss: 0.562728\n",
      "Train Epoch: 5 [158000/240000 (66%)]\tLoss: 0.533088\n",
      "Train Epoch: 5 [159000/240000 (66%)]\tLoss: 0.693823\n",
      "Train Epoch: 5 [160000/240000 (67%)]\tLoss: 0.521977\n",
      "Train Epoch: 5 [161000/240000 (67%)]\tLoss: 0.507858\n",
      "Train Epoch: 5 [162000/240000 (68%)]\tLoss: 0.747729\n",
      "Train Epoch: 5 [163000/240000 (68%)]\tLoss: 0.524193\n",
      "Train Epoch: 5 [164000/240000 (68%)]\tLoss: 0.628098\n",
      "Train Epoch: 5 [165000/240000 (69%)]\tLoss: 0.559102\n",
      "Train Epoch: 5 [166000/240000 (69%)]\tLoss: 0.551500\n",
      "Train Epoch: 5 [167000/240000 (70%)]\tLoss: 0.585129\n",
      "Train Epoch: 5 [168000/240000 (70%)]\tLoss: 0.527625\n",
      "Train Epoch: 5 [169000/240000 (70%)]\tLoss: 0.478309\n",
      "Train Epoch: 5 [170000/240000 (71%)]\tLoss: 0.580395\n",
      "Train Epoch: 5 [171000/240000 (71%)]\tLoss: 0.359919\n",
      "Train Epoch: 5 [172000/240000 (72%)]\tLoss: 0.516658\n",
      "Train Epoch: 5 [173000/240000 (72%)]\tLoss: 0.476022\n",
      "Train Epoch: 5 [174000/240000 (72%)]\tLoss: 0.399466\n",
      "Train Epoch: 5 [175000/240000 (73%)]\tLoss: 0.640144\n",
      "Train Epoch: 5 [176000/240000 (73%)]\tLoss: 0.549581\n",
      "Train Epoch: 5 [177000/240000 (74%)]\tLoss: 0.516978\n",
      "Train Epoch: 5 [178000/240000 (74%)]\tLoss: 0.520075\n",
      "Train Epoch: 5 [179000/240000 (75%)]\tLoss: 0.682189\n",
      "Train Epoch: 5 [180000/240000 (75%)]\tLoss: 0.464101\n",
      "Train Epoch: 5 [181000/240000 (75%)]\tLoss: 0.635196\n",
      "Train Epoch: 5 [182000/240000 (76%)]\tLoss: 0.502694\n",
      "Train Epoch: 5 [183000/240000 (76%)]\tLoss: 0.519786\n",
      "Train Epoch: 5 [184000/240000 (77%)]\tLoss: 0.423602\n",
      "Train Epoch: 5 [185000/240000 (77%)]\tLoss: 0.469242\n",
      "Train Epoch: 5 [186000/240000 (78%)]\tLoss: 0.573273\n",
      "Train Epoch: 5 [187000/240000 (78%)]\tLoss: 0.405850\n",
      "Train Epoch: 5 [188000/240000 (78%)]\tLoss: 0.610918\n",
      "Train Epoch: 5 [189000/240000 (79%)]\tLoss: 0.493109\n",
      "Train Epoch: 5 [190000/240000 (79%)]\tLoss: 0.619836\n",
      "Train Epoch: 5 [191000/240000 (80%)]\tLoss: 0.466023\n",
      "Train Epoch: 5 [192000/240000 (80%)]\tLoss: 0.450386\n",
      "Train Epoch: 5 [193000/240000 (80%)]\tLoss: 0.520944\n",
      "Train Epoch: 5 [194000/240000 (81%)]\tLoss: 0.565330\n",
      "Train Epoch: 5 [195000/240000 (81%)]\tLoss: 0.447710\n",
      "Train Epoch: 5 [196000/240000 (82%)]\tLoss: 0.400006\n",
      "Train Epoch: 5 [197000/240000 (82%)]\tLoss: 0.498510\n",
      "Train Epoch: 5 [198000/240000 (82%)]\tLoss: 0.442878\n",
      "Train Epoch: 5 [199000/240000 (83%)]\tLoss: 0.410574\n",
      "Train Epoch: 5 [200000/240000 (83%)]\tLoss: 0.426760\n",
      "Train Epoch: 5 [201000/240000 (84%)]\tLoss: 0.376495\n",
      "Train Epoch: 5 [202000/240000 (84%)]\tLoss: 0.418715\n",
      "Train Epoch: 5 [203000/240000 (85%)]\tLoss: 0.554689\n",
      "Train Epoch: 5 [204000/240000 (85%)]\tLoss: 0.517441\n",
      "Train Epoch: 5 [205000/240000 (85%)]\tLoss: 0.466451\n",
      "Train Epoch: 5 [206000/240000 (86%)]\tLoss: 0.500180\n",
      "Train Epoch: 5 [207000/240000 (86%)]\tLoss: 0.667019\n",
      "Train Epoch: 5 [208000/240000 (87%)]\tLoss: 0.557332\n",
      "Train Epoch: 5 [209000/240000 (87%)]\tLoss: 0.356510\n",
      "Train Epoch: 5 [210000/240000 (88%)]\tLoss: 0.440145\n",
      "Train Epoch: 5 [211000/240000 (88%)]\tLoss: 0.445105\n",
      "Train Epoch: 5 [212000/240000 (88%)]\tLoss: 0.612689\n",
      "Train Epoch: 5 [213000/240000 (89%)]\tLoss: 0.527707\n",
      "Train Epoch: 5 [214000/240000 (89%)]\tLoss: 0.485708\n",
      "Train Epoch: 5 [215000/240000 (90%)]\tLoss: 0.673999\n",
      "Train Epoch: 5 [216000/240000 (90%)]\tLoss: 0.520766\n",
      "Train Epoch: 5 [217000/240000 (90%)]\tLoss: 0.505328\n",
      "Train Epoch: 5 [218000/240000 (91%)]\tLoss: 0.393493\n",
      "Train Epoch: 5 [219000/240000 (91%)]\tLoss: 0.782779\n",
      "Train Epoch: 5 [220000/240000 (92%)]\tLoss: 0.543938\n",
      "Train Epoch: 5 [221000/240000 (92%)]\tLoss: 0.534977\n",
      "Train Epoch: 5 [222000/240000 (92%)]\tLoss: 0.566388\n",
      "Train Epoch: 5 [223000/240000 (93%)]\tLoss: 0.361312\n",
      "Train Epoch: 5 [224000/240000 (93%)]\tLoss: 0.681198\n",
      "Train Epoch: 5 [225000/240000 (94%)]\tLoss: 0.489738\n",
      "Train Epoch: 5 [226000/240000 (94%)]\tLoss: 0.343376\n",
      "Train Epoch: 5 [227000/240000 (95%)]\tLoss: 0.468318\n",
      "Train Epoch: 5 [228000/240000 (95%)]\tLoss: 0.750426\n",
      "Train Epoch: 5 [229000/240000 (95%)]\tLoss: 0.427818\n",
      "Train Epoch: 5 [230000/240000 (96%)]\tLoss: 0.494740\n",
      "Train Epoch: 5 [231000/240000 (96%)]\tLoss: 0.372254\n",
      "Train Epoch: 5 [232000/240000 (97%)]\tLoss: 0.451990\n",
      "Train Epoch: 5 [233000/240000 (97%)]\tLoss: 0.470115\n",
      "Train Epoch: 5 [234000/240000 (98%)]\tLoss: 0.437784\n",
      "Train Epoch: 5 [235000/240000 (98%)]\tLoss: 0.552794\n",
      "Train Epoch: 5 [236000/240000 (98%)]\tLoss: 0.349293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [237000/240000 (99%)]\tLoss: 0.498106\n",
      "Train Epoch: 5 [238000/240000 (99%)]\tLoss: 0.395772\n",
      "Train Epoch: 5 [239000/240000 (100%)]\tLoss: 0.367916\n",
      "Time elapsed 0:00:54.789812\n",
      "\n",
      "Test set: Average loss: 0.2812, Accuracy: 36821.0/40000 (92%)\n",
      "\n",
      "5 100 0.5\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../results/pytorch_results.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-72ea1de1e8e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../results/pytorch_results.json'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../results/pytorch_results.json'"
     ]
    }
   ],
   "source": [
    "#Parameter Tuning\n",
    "epochs= [5,10,15]\n",
    "batch_size= [100,200,300]\n",
    "dropouts = [.2, .5, .75]\n",
    "layers=[1,2,3,4]\n",
    "\n",
    "score=[]\n",
    "data_dict={}\n",
    "key= 0 \n",
    "for batch in batch_size:\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.EMNIST('data/', train=True, split='digits', download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=batch, shuffle=True, **kwargs)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.EMNIST('data/', train=False, split='digits', transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=batch, shuffle=True, **kwargs)\n",
    "\n",
    "    test_loader_ordered = torch.utils.data.DataLoader(\n",
    "        datasets.EMNIST('data/', train=False, split='digits', transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=len(test_loader.dataset), shuffle=False, **kwargs)\n",
    "    for layer in layers:\n",
    "        for drops in dropouts:\n",
    "            model = models.get_model(n_layers, dropout_rate=drops, n_filters=10, filter_size=5, fc_units=50)\n",
    "\n",
    "            optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.5)\n",
    "            start = datetime.now() \n",
    "            for epoch in epochs:\n",
    "                models.train(model, optimizer, train_loader, use_cuda, device, epoch, layers=layer)\n",
    "                print('Time elapsed {}'.format(datetime.now() - start))\n",
    "                test_loss, correct = models.test(model, optimizer, test_loader, use_cuda, device, epoch, layers=n_layers)\n",
    "                scores = test_loss\n",
    "                print(epoch, batch, drops)\n",
    "\n",
    "                #Save Iterations in Dictionary\n",
    "                data_dict[key]={'layer':layer, 'epoch':epoch, 'batch_size':batch, 'dropout_rate':drops}\n",
    "                score.append(scores)\n",
    "                key += 1  #update Dictionary key\n",
    "\n",
    "data= list(zip(score,data_dict.values()))\n",
    "with open('results/pytorch_results.json','w') as outfile:\n",
    "    json.dump(data,outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
